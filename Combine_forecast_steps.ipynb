{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c07739d",
   "metadata": {},
   "source": [
    "# Combine_forecast steps\n",
    "\n",
    "This notebook breaks the `Combine_forecast.py` pipeline into sequential steps for easier debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e8d33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../slcosmo/other_forecast'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd()\n",
    "if (repo_root / \"LensedUniverse\").is_dir():\n",
    "    workdir = repo_root / \"LensedUniverse\"\n",
    "else:\n",
    "    workdir = repo_root\n",
    "\n",
    "os.chdir(workdir)\n",
    "sys.path.insert(0, str(workdir))\n",
    "\n",
    "# Set test mode and data paths as needed\n",
    "os.environ.setdefault(\"COMBINE_FORECAST_TEST\", \"2\")\n",
    "os.environ.setdefault(\"SLCOSMO_DATA_DIR\", \"../slcosmo\")\n",
    "os.environ.setdefault(\"OTHER_FORECAST_DIR\", \"../slcosmo/other_forecast\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfad2a65",
   "metadata": {},
   "source": [
    "## 1. Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "998f5fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "import arviz as az\n",
    "\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import NUTS, MCMC\n",
    "from jax import random\n",
    "\n",
    "from slcosmo import SLCOSMO, SLmodel, tool\n",
    "\n",
    "TEST_MODE = os.environ.get(\"COMBINE_FORECAST_TEST\") == \"1\"\n",
    "DATA_DIR = os.environ.get(\"SLCOSMO_DATA_DIR\", os.path.join(\"..\", \"slcosmo\"))\n",
    "OTHER_FORECAST_DIR = os.environ.get(\"OTHER_FORECAST_DIR\", os.path.join(\"..\", \"SLCOSMO\", \"other_forecast\"))\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "numpyro.set_platform(\"gpu\")\n",
    "numpyro.enable_x64()\n",
    "\n",
    "slcosmo = SLCOSMO()\n",
    "model_instance = SLmodel(slcosmo)\n",
    "\n",
    "SEED = 42\n",
    "rng_np = np.random.default_rng(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Noisy vs noise-free options (per subprobe)\n",
    "# ---------------------------\n",
    "USE_NOISY_DSPL = False\n",
    "USE_NOISY_LENS = False\n",
    "USE_NOISY_SNE = False\n",
    "USE_NOISY_QUASAR = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5371619e-52cc-41e0-a95d-2315420bca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_MODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9017af9",
   "metadata": {},
   "source": [
    "## 2. Cosmology model & priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e0ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosmology_model(kind, cosmo_prior, sample_h0=True):\n",
    "    cosmo = {\n",
    "        \"Omegam\": numpyro.sample(\"Omegam\", dist.Uniform(cosmo_prior[\"omegam_low\"], cosmo_prior[\"omegam_up\"])),\n",
    "        \"Omegak\": 0.0,\n",
    "        \"w0\": -1.0,\n",
    "        \"wa\": 0.0,\n",
    "        \"h0\": 70.0,\n",
    "    }\n",
    "    if kind in [\"wcdm\", \"owcdm\", \"waw0cdm\", \"owaw0cdm\"]:\n",
    "        cosmo[\"w0\"] = numpyro.sample(\"w0\", dist.Uniform(cosmo_prior[\"w0_low\"], cosmo_prior[\"w0_up\"]))\n",
    "    if kind in [\"waw0cdm\", \"owaw0cdm\"]:\n",
    "        cosmo[\"wa\"] = numpyro.sample(\"wa\", dist.Uniform(cosmo_prior[\"wa_low\"], cosmo_prior[\"wa_up\"]))\n",
    "    if kind in [\"owcdm\", \"owaw0cdm\"]:\n",
    "        cosmo[\"Omegak\"] = numpyro.sample(\"Omegak\", dist.Uniform(cosmo_prior[\"omegak_low\"], cosmo_prior[\"omegak_up\"]))\n",
    "    if sample_h0:\n",
    "        cosmo[\"h0\"] = numpyro.sample(\"h0\", dist.Uniform(cosmo_prior[\"h0_low\"], cosmo_prior[\"h0_up\"]))\n",
    "    return cosmo\n",
    "\n",
    "cosmo_prior = {\n",
    "    \"w0_up\": 0.0,   \"w0_low\": -2.0,\n",
    "    \"wa_up\": 2.0,   \"wa_low\": -2.0,\n",
    "    \"omegak_up\": 1.0, \"omegak_low\": -1.0,\n",
    "    \"h0_up\": 80.0,  \"h0_low\": 60.0,\n",
    "    \"omegam_up\": 0.5, \"omegam_low\": 0.1,\n",
    "}\n",
    "\n",
    "cosmo_true = {\"Omegam\": 0.32, \"Omegak\": 0.0, \"w0\": -1.0, \"wa\": 0.0, \"h0\": 70.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c1e69",
   "metadata": {},
   "source": [
    "## 3. DSPL mock data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %% 1) DSPL mock data (\u03b2 + \u03c3_v)  + 60% photo-z on zs2\n",
    "data_dspl = np.loadtxt(os.path.join(DATA_DIR, \"EuclidDSPLs_1.txt\"))\n",
    "data_dspl = data_dspl[(data_dspl[:, 5] < 0.95)]\n",
    "\n",
    "zl_dspl  = data_dspl[:, 0]\n",
    "zs1_dspl = data_dspl[:, 1]\n",
    "zs2_true_cat = data_dspl[:, 2]\n",
    "\n",
    "beta_err_dspl = data_dspl[:, 6]\n",
    "model_vel_dspl = data_dspl[:, 11]\n",
    "\n",
    "m_ok = (zs2_true_cat > zs1_dspl)\n",
    "zl_dspl  = zl_dspl[m_ok]\n",
    "zs1_dspl = zs1_dspl[m_ok]\n",
    "zs2_true_cat = zs2_true_cat[m_ok]\n",
    "beta_err_dspl = beta_err_dspl[m_ok]\n",
    "model_vel_dspl = model_vel_dspl[m_ok]\n",
    "\n",
    "N_dspl = len(zl_dspl)\n",
    "print(\"N_dspl after zs2>zs1 cut =\", N_dspl)\n",
    "\n",
    "# --- 60% systems use photo-z on zs2 with sigma=0.1\n",
    "is_photo = (rng_np.random(N_dspl) < 0.60)\n",
    "zs2_err = np.where(is_photo, 0.1, 1e-4)\n",
    "zs2_obs = zs2_true_cat + rng_np.normal(0.0, zs2_err)\n",
    "\n",
    "# --- enforce zs2_obs > zs1\n",
    "eps = 1e-3\n",
    "bad = zs2_obs <= (zs1_dspl + eps)\n",
    "for _ in range(20):\n",
    "    if not np.any(bad):\n",
    "        break\n",
    "    zs2_obs[bad] = zs2_true_cat[bad] + rng_np.normal(0.0, zs2_err[bad])\n",
    "    bad = zs2_obs <= (zs1_dspl + eps)\n",
    "zs2_obs = np.maximum(zs2_obs, zs1_dspl + eps)\n",
    "\n",
    "Dl1, Ds1, Dls1 = tool.compute_distances(zl_dspl, zs1_dspl, cosmo_true)\n",
    "Dl2, Ds2, Dls2 = tool.compute_distances(zl_dspl, zs2_true_cat, cosmo_true)\n",
    "beta_geom_dspl = Dls1 * Ds2 / (Ds1 * Dls2)\n",
    "\n",
    "lambda_true_dspl = tool.truncated_normal(1.0, 0.05, 0.85, 1.15, N_dspl, random_state=rng_np)\n",
    "lambda_err_dspl = lambda_true_dspl * 0.06\n",
    "\n",
    "true_vel_dspl = model_vel_dspl * jnp.sqrt(lambda_true_dspl)\n",
    "vel_err_dspl = 0.03 * true_vel_dspl\n",
    "\n",
    "beta_true_dspl = tool.beta_antimst(beta_geom_dspl, mst=lambda_true_dspl)\n",
    "\n",
    "if USE_NOISY_DSPL:\n",
    "    lambda_obs_dspl = lambda_true_dspl + np.random.normal(0.0, lambda_err_dspl)\n",
    "    obs_vel_dspl = true_vel_dspl + np.random.normal(0.0, vel_err_dspl)\n",
    "    beta_obs_dspl = tool.truncated_normal(beta_true_dspl, beta_err_dspl, 0.0, 1.0, random_state=rng_np)\n",
    "    zs2_use = zs2_obs\n",
    "else:\n",
    "    lambda_obs_dspl = lambda_true_dspl\n",
    "    obs_vel_dspl = true_vel_dspl\n",
    "    beta_obs_dspl = beta_true_dspl\n",
    "    zs2_use = zs2_true_cat\n",
    "\n",
    "dspl_data = {\n",
    "    \"zl\": zl_dspl,\n",
    "    \"zs1\": zs1_dspl,\n",
    "    \"zs2_cat\": zs2_true_cat,\n",
    "    \"zs2_obs\": zs2_use,\n",
    "    \"zs2_err\": zs2_err,\n",
    "    \"is_photo\": is_photo.astype(np.int32),\n",
    "    \"beta_obs\": beta_obs_dspl,\n",
    "    \"beta_err\": beta_err_dspl,\n",
    "    \"v_model\": model_vel_dspl,\n",
    "    \"v_obs\": obs_vel_dspl,\n",
    "    \"v_err\": vel_err_dspl,\n",
    "    \"lambda_err\": lambda_err_dspl,\n",
    "    \"lambda_obs\": lambda_obs_dspl,\n",
    "}\n",
    "\n",
    "photo_z = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfa1d5",
   "metadata": {},
   "source": [
    "## 4. Lens + kinematics mock data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %% 2) Lens+kin mock data (E, \u03b3, \u03b2_aniso, \u03c3_v)\n",
    "LUT = np.load(os.path.join(DATA_DIR, \"velocity_disp_table.npy\"))\n",
    "N1, N2, N3, N4 = LUT.shape\n",
    "thetaE_grid = np.linspace(0.5, 3.0, N1)\n",
    "gamma_grid  = np.linspace(1.2, 2.8, N2)\n",
    "Re_grid     = np.linspace(0.15, 3.0, N3)\n",
    "beta_grid   = np.linspace(-0.5, 0.8, N4)\n",
    "jampy_interp = tool.make_4d_interpolant(thetaE_grid, gamma_grid, Re_grid, beta_grid, LUT)\n",
    "\n",
    "Euclid_GG_data = np.loadtxt(os.path.join(DATA_DIR, \"Euclid_len.txt\"))\n",
    "zl_lens = Euclid_GG_data[:, 0]\n",
    "zs_lens = Euclid_GG_data[:, 1]\n",
    "Ein_lens = Euclid_GG_data[:, 2]\n",
    "re_lens = Euclid_GG_data[:, 5]\n",
    "\n",
    "mask_lens = (Ein_lens >= 0.6) & (re_lens >= 0.25) & (re_lens <= 2.8)\n",
    "zl_lens = zl_lens[mask_lens]\n",
    "zs_lens = zs_lens[mask_lens]\n",
    "thetaE_lens = Ein_lens[mask_lens]\n",
    "re_lens = re_lens[mask_lens]\n",
    "\n",
    "dl_lens, ds_lens, dls_lens = tool.dldsdls(zl_lens, zs_lens, cosmo_true, n=20)\n",
    "N_lens = len(zl_lens)\n",
    "\n",
    "gamma_true_lens = tool.truncated_normal(2.0, 0.2, 1.5, 2.5, N_lens, random_state=rng_np)\n",
    "beta_true_lens  = tool.truncated_normal(0.0, 0.2, -0.4, 0.4, N_lens, random_state=rng_np)\n",
    "vel_model_lens = jampy_interp(thetaE_lens, gamma_true_lens, re_lens, beta_true_lens) * jnp.sqrt(ds_lens / dls_lens)\n",
    "lambda_true_lens = tool.truncated_normal(1.0, 0.05, 0.8, 1.2, N_lens, random_state=rng_np)\n",
    "vel_true_lens = vel_model_lens * jnp.sqrt(lambda_true_lens)\n",
    "\n",
    "theta_E_err = 0.01 * thetaE_lens\n",
    "vel_err_lens = 0.10 * vel_true_lens\n",
    "\n",
    "if USE_NOISY_LENS:\n",
    "    gamma_obs_lens = gamma_true_lens + tool.truncated_normal(0.0, 0.05, -0.2, 0.2, N_lens, random_state=rng_np)\n",
    "    thetaE_lens_obs = thetaE_lens + np.random.normal(0.0, theta_E_err)\n",
    "    vel_obs_lens = np.random.normal(vel_true_lens, vel_err_lens)\n",
    "else:\n",
    "    gamma_obs_lens = gamma_true_lens\n",
    "    thetaE_lens_obs = thetaE_lens\n",
    "    vel_obs_lens = vel_true_lens\n",
    "\n",
    "lens_data = {\n",
    "    \"zl\": zl_lens,\n",
    "    \"zs\": zs_lens,\n",
    "    \"theta_E\": thetaE_lens_obs,\n",
    "    \"theta_E_err\": theta_E_err,\n",
    "    \"re\": re_lens,\n",
    "    \"gamma_obs\": gamma_obs_lens,\n",
    "    \"vel_obs\": vel_obs_lens,\n",
    "    \"vel_err\": vel_err_lens,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde095ae",
   "metadata": {},
   "source": [
    "## 5. Lensed SNe mock data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %% 3) Lensed SNe mock data (time-delay likelihood)\n",
    "sn_data = pd.read_csv(os.path.join(DATA_DIR, \"Euclid_150SNe.csv\"))\n",
    "sn_data = sn_data[(sn_data[\"tmax\"] >= 5) & (sn_data[\"tmax\"] <= 80)]\n",
    "sn_data = sn_data.nlargest(70, 'tmax')\n",
    "zl_sne = np.array(sn_data[\"zl\"])\n",
    "zs_sne = np.array(sn_data[\"z_host\"])\n",
    "t_delay_true_days = np.array(sn_data[\"tmax\"])\n",
    "\n",
    "Dl_sne, Ds_sne, Dls_sne = tool.dldsdls(zl_sne, zs_sne, cosmo_true, n=20)\n",
    "Ddt_geom_sne = (1.0 + zl_sne) * Dl_sne * Ds_sne / Dls_sne\n",
    "\n",
    "N_sne = len(zl_sne)\n",
    "# Parent population for MST (lambda)\n",
    "lambda_pop_mean = 1.0\n",
    "lambda_pop_sigma = 0.05\n",
    "lambda_low, lambda_high = 0.8, 1.2\n",
    "lambda_true_sne = tool.truncated_normal(lambda_pop_mean, lambda_pop_sigma, lambda_low, lambda_high, N_sne, random_state=rng_np)\n",
    "\n",
    "seconds_per_day = 86400.0\n",
    "Mpc_km = tool.Mpc / 1000.0\n",
    "\n",
    "# Fermat potential difference from baseline time delay (no MST in phi)\n",
    "fermat_phi_true = (tool.c_km_s * t_delay_true_days * seconds_per_day) / (Ddt_geom_sne * Mpc_km)\n",
    "\n",
    "# Time-delay true includes MST transform\n",
    "t_delay_true_mst = t_delay_true_days * lambda_true_sne\n",
    "\n",
    "# Measurement errors (assumed in likelihood)\n",
    "sigma_t_days = 1.0\n",
    "sigma_phi_frac = 0.04\n",
    "sigma_lambda_frac = 0.08\n",
    "\n",
    "# Observed quantities (noisy vs noise-free)\n",
    "if USE_NOISY_SNE:\n",
    "    t_delay_obs = t_delay_true_mst + np.random.normal(0.0, sigma_t_days, size=N_sne)\n",
    "    fermat_phi_obs = fermat_phi_true + np.random.normal(0.0, sigma_phi_frac * np.abs(fermat_phi_true))\n",
    "    lambda_obs_sne = lambda_true_sne + np.random.normal(0.0, sigma_lambda_frac * np.abs(lambda_true_sne))\n",
    "else:\n",
    "    t_delay_obs = t_delay_true_mst.copy()\n",
    "    fermat_phi_obs = fermat_phi_true.copy()\n",
    "    lambda_obs_sne = lambda_true_sne.copy()\n",
    "\n",
    "lambda_err_sne = sigma_lambda_frac * np.abs(lambda_obs_sne)\n",
    "\n",
    "# Scale phi\n",
    "\n",
    "def scale_phi(phi_obs):\n",
    "    finite = np.isfinite(phi_obs) & (phi_obs != 0)\n",
    "    if not np.any(finite):\n",
    "        return phi_obs, 1.0\n",
    "    median = np.median(np.abs(phi_obs[finite]))\n",
    "    if (not np.isfinite(median)) or median == 0:\n",
    "        return phi_obs, 1.0\n",
    "    exp = int(np.round(-np.log10(median)))\n",
    "    scale = 10.0 ** exp\n",
    "    return phi_obs * scale, scale\n",
    "\n",
    "fermat_phi_obs_scaled, phi_scale_sne = scale_phi(fermat_phi_obs)\n",
    "\n",
    "sne_data = {\n",
    "    \"zl\": zl_sne,\n",
    "    \"zs\": zs_sne,\n",
    "    \"t_obs\": t_delay_obs,\n",
    "    \"phi_obs\": fermat_phi_obs_scaled,\n",
    "    \"phi_scale\": phi_scale_sne,\n",
    "    \"lambda_obs\": lambda_obs_sne,\n",
    "    \"lambda_err\": lambda_err_sne,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %% 4) Lensed Quasar mock data (time-delay likelihood)\n",
    "DATA_JSON = Path(\"../Temp_data/static_datavectors_seed6.json\")\n",
    "with DATA_JSON.open(\"r\") as f:\n",
    "    quasar_blocks = json.load(f)\n",
    "\n",
    "z_lens_list = []\n",
    "z_src_list = []\n",
    "t_base_list = []\n",
    "t_err_list = []\n",
    "block_id_list = []\n",
    "\n",
    "for b, block in enumerate(quasar_blocks):\n",
    "    z_lens = np.asarray(block[\"z_lens\"], dtype=float)\n",
    "    z_src = np.asarray(block[\"z_src\"], dtype=float)\n",
    "\n",
    "    td = np.asarray(block[\"td_measured\"], dtype=float)\n",
    "    td_mean = td.mean(axis=1)\n",
    "\n",
    "    n_lens, n_td = td_mean.shape\n",
    "    if n_td == 3:\n",
    "        idx = np.argmax(np.abs(td_mean), axis=1)\n",
    "        t_base = np.abs(td_mean[np.arange(n_lens), idx])\n",
    "    else:\n",
    "        t_base = np.abs(td_mean[:, 0])\n",
    "\n",
    "    if b in (0, 1, 2):\n",
    "        t_err = 0.03 * t_base\n",
    "    else:\n",
    "        t_err = np.full_like(t_base, 5.0)\n",
    "\n",
    "    z_lens_list.append(z_lens)\n",
    "    z_src_list.append(z_src)\n",
    "    t_base_list.append(t_base)\n",
    "    t_err_list.append(t_err)\n",
    "    block_id_list.append(np.full(n_lens, b, dtype=int))\n",
    "\n",
    "z_lens_q = np.concatenate(z_lens_list)\n",
    "z_src_q = np.concatenate(z_src_list)\n",
    "t_base_q = np.concatenate(t_base_list)\n",
    "t_err_q = np.concatenate(t_err_list)\n",
    "block_id_q = np.concatenate(block_id_list)\n",
    "\n",
    "zl_j = jnp.asarray(z_lens_q)\n",
    "zs_j = jnp.asarray(z_src_q)\n",
    "Dl_q, Ds_q, Dls_q = tool.dldsdls(zl_j, zs_j, cosmo_true, n=20)\n",
    "Ddt_geom_q = (1.0 + zl_j) * Dl_q * Ds_q / Dls_q\n",
    "Ddt_geom_q = np.asarray(Ddt_geom_q)\n",
    "\n",
    "c_km_day = tool.c_km_s * 86400.0\n",
    "Mpc_km = tool.Mpc / 1000.0\n",
    "\n",
    "phi_true_q = (c_km_day * t_base_q) / (Ddt_geom_q * Mpc_km)\n",
    "\n",
    "phi_err_frac_by_block = {\n",
    "    0: 0.02,\n",
    "    1: 0.05,\n",
    "    2: 0.05,\n",
    "    3: 0.11,\n",
    "    4: 0.11,\n",
    "    5: 0.18,\n",
    "    6: 0.18,\n",
    "    7: 0.18,\n",
    "    8: 0.18,\n",
    "}\n",
    "\n",
    "sigma_v_frac_by_block = {\n",
    "    0: 0.03,\n",
    "    1: 0.03,\n",
    "    2: 0.03,\n",
    "    3: 0.10,\n",
    "    4: 0.10,\n",
    "    5: 0.10,\n",
    "    6: 0.10,\n",
    "    7: np.nan,\n",
    "    8: np.nan,\n",
    "}\n",
    "\n",
    "phi_err_frac_q = np.asarray([phi_err_frac_by_block[b] for b in block_id_q])\n",
    "phi_err_q = phi_err_frac_q * np.abs(phi_true_q)\n",
    "\n",
    "lambda_true_q = tool.truncated_normal(1.0, 0.05, 0.8, 1.2, z_lens_q.size, random_state=rng_np)\n",
    "\n",
    "sigma_v_frac_q = np.asarray([sigma_v_frac_by_block[b] for b in block_id_q])\n",
    "mst_mask_q = np.isfinite(sigma_v_frac_q)\n",
    "mst_err_frac_q = 2.0 * sigma_v_frac_q\n",
    "lambda_err_q = np.where(\n",
    "    np.isfinite(mst_err_frac_q),\n",
    "    mst_err_frac_q * np.abs(lambda_true_q),\n",
    "    0.05,\n",
    ")\n",
    "\n",
    "t_true_q = t_base_q * lambda_true_q\n",
    "\n",
    "if USE_NOISY_QUASAR:\n",
    "    t_obs_q = t_true_q + rng_np.normal(0.0, t_err_q)\n",
    "    phi_obs_q = phi_true_q + rng_np.normal(0.0, phi_err_q)\n",
    "    lambda_obs_q = lambda_true_q + rng_np.normal(0.0, lambda_err_q)\n",
    "else:\n",
    "    t_obs_q = t_true_q.copy()\n",
    "    phi_obs_q = phi_true_q.copy()\n",
    "    lambda_obs_q = lambda_true_q.copy()\n",
    "\n",
    "phi_obs_q_scaled, phi_scale_q = scale_phi(phi_obs_q)\n",
    "phi_err_q_scaled = phi_err_frac_q * np.abs(phi_obs_q_scaled)\n",
    "\n",
    "quasar_data = {\n",
    "    \"zl\": z_lens_q,\n",
    "    \"zs\": z_src_q,\n",
    "    \"t_obs\": t_obs_q,\n",
    "    \"t_err\": t_err_q,\n",
    "    \"phi_obs\": phi_obs_q_scaled,\n",
    "    \"phi_err\": phi_err_q_scaled,\n",
    "    \"phi_scale\": phi_scale_q,\n",
    "    \"lambda_obs\": lambda_obs_q,\n",
    "    \"lambda_err\": lambda_err_q,\n",
    "    \"mst_mask\": mst_mask_q,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a46504",
   "metadata": {},
   "source": [
    "## 6. Joint model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def joint_model(dspl_data=None, lens_data=None, sne_data=None, quasar_data=None):\n",
    "    cosmo = cosmology_model(\"waw0cdm\", cosmo_prior, sample_h0=True)\n",
    "\n",
    "    lambda_mean = numpyro.sample(\"lambda_mean\", dist.Uniform(0.9, 1.1))\n",
    "    lambda_sigma = numpyro.sample(\"lambda_sigma\", dist.TruncatedNormal(0.05, 0.5, low=0.0, high=0.2))\n",
    "\n",
    "    gamma_mean = numpyro.sample(\"gamma_mean\", dist.Uniform(1.6, 2.4))\n",
    "    gamma_sigma = numpyro.sample(\"gamma_sigma\", dist.TruncatedNormal(0.2, 0.2, low=0.0, high=0.4))\n",
    "\n",
    "    beta_mean = numpyro.sample(\"beta_mean\", dist.Uniform(-0.3, 0.3))\n",
    "    beta_sigma = numpyro.sample(\"beta_sigma\", dist.TruncatedNormal(0.2, 0.2, low=0.0, high=0.4))\n",
    "\n",
    "    if dspl_data is not None:\n",
    "        zl = dspl_data[\"zl\"]\n",
    "        zs1 = dspl_data[\"zs1\"]\n",
    "        zs2_obs = dspl_data[\"zs2_obs\"]\n",
    "        zs2_err = dspl_data[\"zs2_err\"]\n",
    "        is_photo = dspl_data[\"is_photo\"]\n",
    "        beta_obs = dspl_data[\"beta_obs\"]\n",
    "        beta_err = dspl_data[\"beta_err\"]\n",
    "        v_model = dspl_data[\"v_model\"]\n",
    "        v_obs = dspl_data[\"v_obs\"]\n",
    "        v_err = dspl_data[\"v_err\"]\n",
    "        lambda_obs = dspl_data[\"lambda_obs\"]\n",
    "        lambda_err = dspl_data[\"lambda_err\"]\n",
    "\n",
    "        Dl1, Ds1, Dls1 = tool.compute_distances(zl, zs1, cosmo)\n",
    "        Dl2, Ds2, Dls2 = tool.compute_distances(zl, zs2_obs, cosmo)\n",
    "        beta_geom = Dls1 * Ds2 / (Ds1 * Dls2)\n",
    "\n",
    "        N_dspl = len(zl)\n",
    "        with numpyro.plate(\"dspl\", N_dspl):\n",
    "            lambda_dspl = numpyro.sample(\n",
    "                \"lambda_dspl\",\n",
    "                dist.TruncatedNormal(lambda_mean, lambda_sigma, low=0.8, high=1.2),\n",
    "            )\n",
    "            numpyro.sample(\n",
    "                \"lambda_dspl_like\",\n",
    "                dist.Normal(lambda_dspl, lambda_err),\n",
    "                obs=lambda_obs,\n",
    "            )\n",
    "            beta_mst = tool.beta_antimst(beta_geom, lambda_dspl)\n",
    "            numpyro.sample(\n",
    "                \"beta_dspl_like\",\n",
    "                dist.TruncatedNormal(beta_mst, beta_err, low=0.0, high=1.0),\n",
    "                obs=beta_obs,\n",
    "            )\n",
    "\n",
    "    if lens_data is not None:\n",
    "        dl_lens, ds_lens, dls_lens = tool.dldsdls(lens_data[\"zl\"], lens_data[\"zs\"], cosmo, n=20)\n",
    "        N_lens = len(lens_data[\"zl\"])\n",
    "        with numpyro.plate(\"lens\", N_lens):\n",
    "            gamma_i = numpyro.sample(\n",
    "                \"gamma_i\",\n",
    "                dist.TruncatedNormal(gamma_mean, gamma_sigma, low=1.6, high=2.4),\n",
    "            )\n",
    "            beta_i = numpyro.sample(\n",
    "                \"beta_i\",\n",
    "                dist.TruncatedNormal(beta_mean, beta_sigma, low=-0.4, high=0.4),\n",
    "            )\n",
    "            lambda_lens = numpyro.sample(\n",
    "                \"lambda_lens\",\n",
    "                dist.TruncatedNormal(lambda_mean, lambda_sigma, low=0.8, high=1.2),\n",
    "            )\n",
    "            theta_E_i = numpyro.sample(\n",
    "                \"theta_E_i\",\n",
    "                dist.Normal(lens_data[\"theta_E\"], lens_data[\"theta_E_err\"]),\n",
    "            )\n",
    "            v_interp = jampy_interp(theta_E_i, gamma_i, lens_data[\"re\"], beta_i)\n",
    "            vel_pred = v_interp * jnp.sqrt(ds_lens / dls_lens) * jnp.sqrt(lambda_lens)\n",
    "\n",
    "            numpyro.sample(\n",
    "                \"gamma_obs_lens\",\n",
    "                dist.Normal(gamma_i, 0.05),\n",
    "                obs=lens_data[\"gamma_obs\"],\n",
    "            )\n",
    "            numpyro.sample(\n",
    "                \"vel_lens_like\",\n",
    "                dist.Normal(vel_pred, lens_data[\"vel_err\"]),\n",
    "                obs=lens_data[\"vel_obs\"],\n",
    "            )\n",
    "\n",
    "    if sne_data is not None:\n",
    "        Dl_sne, Ds_sne, Dls_sne = tool.dldsdls(sne_data[\"zl\"], sne_data[\"zs\"], cosmo, n=20)\n",
    "        Ddt_geom = (1.0 + sne_data[\"zl\"]) * Dl_sne * Ds_sne / Dls_sne\n",
    "        N_sne = len(sne_data[\"zl\"])\n",
    "\n",
    "        t_obs = sne_data[\"t_obs\"]\n",
    "        phi_obs = sne_data[\"phi_obs\"]\n",
    "        phi_scale = sne_data[\"phi_scale\"]\n",
    "        lambda_obs = sne_data[\"lambda_obs\"]\n",
    "        lambda_err = sne_data[\"lambda_err\"]\n",
    "        sigma_phi = sigma_phi_frac * phi_obs\n",
    "\n",
    "        with numpyro.plate(\"sne\", N_sne):\n",
    "            phi_true_scaled = numpyro.sample(\"phi_true_scaled_sne\", dist.TruncatedNormal(phi_obs, sigma_phi, low=0.0, high=10.0))\n",
    "            lambda_sne = numpyro.sample(\"lambda_sne\", dist.TruncatedNormal(lambda_mean, lambda_sigma, low=0.8, high=1.2))\n",
    "            numpyro.sample(\n",
    "                \"lambda_sne_like\",\n",
    "                dist.Normal(lambda_sne, lambda_err),\n",
    "                obs=lambda_obs,\n",
    "            )\n",
    "\n",
    "            phi_true = phi_true_scaled / phi_scale\n",
    "            Ddt_true = Ddt_geom * lambda_sne\n",
    "            t_model_days = (Ddt_true * Mpc_km / tool.c_km_s) * phi_true / seconds_per_day\n",
    "            numpyro.sample(\n",
    "                \"t_delay_sne_like\",\n",
    "                dist.Normal(t_model_days, sigma_t_days),\n",
    "                obs=t_obs,\n",
    "            )\n",
    "\n",
    "    if quasar_data is not None:\n",
    "        Dl_q, Ds_q, Dls_q = tool.dldsdls(quasar_data[\"zl\"], quasar_data[\"zs\"], cosmo, n=20)\n",
    "        Ddt_geom_q = (1.0 + quasar_data[\"zl\"]) * Dl_q * Ds_q / Dls_q\n",
    "        N_q = len(quasar_data[\"zl\"])\n",
    "\n",
    "        t_obs = quasar_data[\"t_obs\"]\n",
    "        t_err = quasar_data[\"t_err\"]\n",
    "        phi_obs = quasar_data[\"phi_obs\"]\n",
    "        phi_err = quasar_data[\"phi_err\"]\n",
    "        phi_scale = quasar_data[\"phi_scale\"]\n",
    "        lambda_obs = quasar_data[\"lambda_obs\"]\n",
    "        lambda_err = quasar_data[\"lambda_err\"]\n",
    "        mst_mask = jnp.asarray(quasar_data[\"mst_mask\"])\n",
    "\n",
    "        with numpyro.plate(\"quasar\", N_q):\n",
    "            phi_true_scaled = numpyro.sample(\"phi_true_scaled_q\", dist.Normal(phi_obs, phi_err))\n",
    "            lambda_q = numpyro.sample(\"lambda_q\", dist.TruncatedNormal(lambda_mean, lambda_sigma, low=0.8, high=1.2))\n",
    "            numpyro.sample(\"lambda_q_like\", dist.Normal(lambda_q, lambda_err).mask(mst_mask), obs=lambda_obs)\n",
    "\n",
    "            phi_true = phi_true_scaled / phi_scale\n",
    "            Ddt_true = Ddt_geom_q * lambda_q\n",
    "            t_model_days = (Ddt_true * Mpc_km / tool.c_km_s) * phi_true / seconds_per_day\n",
    "            numpyro.sample(\"t_delay_q_like\", dist.Normal(t_model_days, t_err), obs=t_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def head_dict(data_dict, N_use=None):\n",
    "    out = {}\n",
    "    for k, v in data_dict.items():\n",
    "        arr = jnp.asarray(v)\n",
    "        if arr.shape == ():\n",
    "            out[k] = arr\n",
    "        else:\n",
    "            out[k] = arr[:N_use] if N_use is not None else arr\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2e20e",
   "metadata": {},
   "source": [
    "## 7. Run MCMC (test-mode defaults)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if TEST_MODE:\n",
    "    N_DSPL_USE = 50\n",
    "    N_LENS_USE = 200\n",
    "    N_SNE_USE = 10\n",
    "    N_QUASAR_USE = 30\n",
    "    num_warmup = 200\n",
    "    num_samples = 200\n",
    "    num_chains = 2\n",
    "    chain_method = \"sequential\"\n",
    "else:\n",
    "    N_DSPL_USE = 1200\n",
    "    N_LENS_USE = 5000\n",
    "    N_SNE_USE = 50\n",
    "    N_QUASAR_USE = 500\n",
    "    num_warmup = 500\n",
    "    num_samples = 1500\n",
    "    num_chains = 8\n",
    "    chain_method = \"vectorized\"\n",
    "\n",
    "dspl_data = head_dict(dspl_data, N_DSPL_USE)\n",
    "lens_data = head_dict(lens_data, N_LENS_USE)\n",
    "sne_data  = head_dict(sne_data,  N_SNE_USE)\n",
    "quasar_data = head_dict(quasar_data, N_QUASAR_USE)\n",
    "\n",
    "init_values = {\n",
    "    \"h0\": 70.0,\n",
    "    \"Omegam\": 0.32,\n",
    "    \"w0\": -1.0,\n",
    "    \"wa\": 0.0,\n",
    "    \"lambda_mean\": 1.0,\n",
    "    \"lambda_sigma\": 0.05,\n",
    "    \"gamma_mean\": 2.0,\n",
    "    \"gamma_sigma\": 0.2,\n",
    "    \"beta_mean\": 0.0,\n",
    "    \"beta_sigma\": 0.2,\n",
    "}\n",
    "\n",
    "from numpyro.infer import init_to_value\n",
    "init_strategy = init_to_value(values=init_values)\n",
    "\n",
    "nuts_kernel = NUTS(\n",
    "    joint_model,\n",
    "    target_accept_prob=0.8,\n",
    "    dense_mass=[(\"wa\", \"w0\", \"h0\", \"Omegam\", \"lambda_mean\")],\n",
    "    init_strategy=init_strategy,\n",
    ")\n",
    "mcmc = MCMC(\n",
    "    nuts_kernel,\n",
    "    num_warmup=num_warmup,\n",
    "    num_samples=num_samples,\n",
    "    num_chains=num_chains,\n",
    "    chain_method=chain_method,\n",
    "    progress_bar=True,\n",
    ")\n",
    "\n",
    "rng_key = random.PRNGKey(0)\n",
    "mcmc.run(rng_key, dspl_data=dspl_data, sne_data=sne_data, lens_data=lens_data, quasar_data=quasar_data)\n",
    "\n",
    "posterior = jax.device_get(mcmc.get_samples(group_by_chain=True))\n",
    "sample_stats = jax.device_get(mcmc.get_extra_fields(group_by_chain=True))\n",
    "inf_data = az.from_dict(posterior=posterior, sample_stats=sample_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19de636f-5f9c-4e8f-be77-37ae151ee5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: result/Lens_revolution_summary.csv\n",
      "Saved: result/Lens_revolution.nc\n"
     ]
    }
   ],
   "source": [
    "result_dir = \"/mnt/lustre/tianli/LensedUniverse_result\"\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "nc_filename = os.path.join(result_dir, \"Lens_revolution\")\n",
    "fig_dir = Path(\"result\")\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "base_name = os.path.basename(nc_filename)\n",
    "summary_df = az.summary(\n",
    "    inf_data,\n",
    "    var_names=[\"wa\", \"w0\", \"h0\", \"Omegam\"],round_to=4\n",
    ")\n",
    "summary_df.to_csv(nc_filename + \"_summary.csv\")\n",
    "az.to_netcdf(inf_data, nc_filename + \".nc\")\n",
    "\n",
    "print(\"Saved:\", nc_filename + \"_summary.csv\")\n",
    "print(\"Saved:\", nc_filename + \".nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39217b",
   "metadata": {},
   "source": [
    "## 8. Plots and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9449eaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed no burn in\n",
      "Removed no burn in\n",
      "Removed no burn in\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4063"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "from getdist import plots, MCSamples\n",
    "corner_vars = [\n",
    "    \"h0\", \"Omegam\", \"w0\", \"wa\",\n",
    "    \"gamma_mean\", \"gamma_sigma\",\n",
    "    \"beta_mean\", \"beta_sigma\",\n",
    "    \"lambda_mean\", \"lambda_sigma\",\n",
    "]\n",
    "truths = [70, 0.32, -1.0, 0.0, 2.0, 0.2, 0.0, 0.2, 1.0, 0.05]\n",
    "\n",
    "fig = corner.corner(inf_data, truths=truths, var_names=corner_vars, show_title=True)\n",
    "fig.savefig(fig_dir / f\"{base_name}.pdf\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ============================\n",
    "# 1. Read three w0, wa samples\n",
    "# ============================\n",
    "posterior_supernovae = pd.DataFrame(\n",
    "    np.genfromtxt(os.path.join(OTHER_FORECAST_DIR, \"Y10_SN.txt\")),\n",
    "    columns=[\"Omega_m\", \"sigma_8\", \"n_s\", \"w_0\", \"w_a\", \"Omega_b\", \"H_0\"],\n",
    ")\n",
    "samples_supernovae = posterior_supernovae[[\"w_0\", \"w_a\"]].to_numpy()\n",
    "\n",
    "param_names_all = [\n",
    "    \"Omegam\", \"Omegab\", \"w0\", \"wa\", \"h\", \"ns\", \"sigma8\",\n",
    "    \"aIA\", \"etaIA\", \"betaIA\", \"b1\", \"b2\", \"b3\", \"b4\", \"b5\",\n",
    "    \"b6\", \"b7\", \"b8\", \"b9\", \"b10\",\n",
    "]\n",
    "\n",
    "fisher_matrix = np.genfromtxt(os.path.join(OTHER_FORECAST_DIR, \"EuclidISTF_WL_w0wa_flat_pessimistic.txt\"))\n",
    "covariance_matrix = np.linalg.inv(fisher_matrix)\n",
    "\n",
    "idx_w0 = param_names_all.index(\"w0\")\n",
    "idx_wa = param_names_all.index(\"wa\")\n",
    "cov_sub = covariance_matrix[np.ix_([idx_w0, idx_wa], [idx_w0, idx_wa])]\n",
    "\n",
    "mean_w0 = -1.0\n",
    "mean_wa = 0.0\n",
    "mean = [mean_w0, mean_wa]\n",
    "\n",
    "num_samples = 10000\n",
    "samples_Euclid = np.random.multivariate_normal(mean, cov_sub, size=num_samples)\n",
    "\n",
    "idata = az.from_netcdf(nc_filename + \".nc\")\n",
    "w0_joint = idata.posterior[\"w0\"].values.reshape(-1)\n",
    "wa_joint = idata.posterior[\"wa\"].values.reshape(-1)\n",
    "w0_joint = w0_joint - np.mean(w0_joint) - 1\n",
    "wa_joint = wa_joint - np.mean(wa_joint)\n",
    "samples_joint = np.vstack([w0_joint, wa_joint]).T\n",
    "\n",
    "# ============================\n",
    "# 2. Convert to GetDist\n",
    "# ============================\n",
    "\n",
    "names = [\"w0\", \"wa\"]\n",
    "labels = [r\"w_0\", r\"w_a\"]\n",
    "\n",
    "mc_sne = MCSamples(\n",
    "    samples=samples_supernovae,\n",
    "    names=names,\n",
    "    labels=labels,\n",
    "    settings={\"smooth_scale_2D\": 0.5},\n",
    ")\n",
    "\n",
    "mc_euclid = MCSamples(\n",
    "    samples=samples_Euclid,\n",
    "    names=names,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "mc_joint = MCSamples(\n",
    "    samples=samples_joint,\n",
    "    names=names,\n",
    "    labels=labels,\n",
    "    settings={\"smooth_scale_2D\": 0.5},\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 3. GetDist 2D plot\n",
    "# ============================\n",
    "\n",
    "g = plots.get_subplot_plotter(subplot_size=5)\n",
    "\n",
    "g.plot_2d(\n",
    "    [mc_sne, mc_euclid, mc_joint],\n",
    "    param_pair=(\"w0\", \"wa\"),\n",
    "    filled=[True, True, True],\n",
    "    line_args=[\n",
    "        {\"ls\": \"--\", \"alpha\": 0.7, \"lw\": 2},\n",
    "        {\"ls\": \"--\", \"alpha\": 0.7, \"lw\": 2},\n",
    "        {\"ls\": \"-\", \"lw\": 2},\n",
    "    ],\n",
    "    colors=[\"orange\", \"green\", \"black\"],\n",
    ")\n",
    "\n",
    "g.add_legend(\n",
    "    [\"LSST SNe\", \"Euclid Weak Lensing\", \"Strong Lensing Y10\"],\n",
    "    frameon=True,\n",
    "    framealpha=0.8,\n",
    "    edgecolor=\"black\",\n",
    "    facecolor=\"white\",\n",
    "    fontsize=10,\n",
    "    legend_loc=\"upper left\",\n",
    ")\n",
    "\n",
    "g.export(str(fig_dir / f\"{base_name}compare.pdf\"))\n",
    "plt.close(g.fig)\n",
    "del g\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48a581-43b4-4fd7-9a5f-0432d833cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Herculens_Tian",
   "language": "python",
   "name": "herculens_tian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}