{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8c07739d",
      "metadata": {},
      "source": [
        "# Combine_forecast steps\n",
        "\n",
        "This notebook breaks the `Combine_forecast.py` pipeline into sequential steps for easier debugging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d7e8d33b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'../slcosmo/other_forecast'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "repo_root = Path.cwd()\n",
        "if (repo_root / \"LensedUniverse\").is_dir():\n",
        "    workdir = repo_root / \"LensedUniverse\"\n",
        "else:\n",
        "    workdir = repo_root\n",
        "\n",
        "os.chdir(workdir)\n",
        "sys.path.insert(0, str(workdir))\n",
        "\n",
        "# Set test mode and data paths as needed\n",
        "os.environ.setdefault(\"COMBINE_FORECAST_TEST\", \"2\")\n",
        "os.environ.setdefault(\"SLCOSMO_DATA_DIR\", \"../slcosmo\")\n",
        "os.environ.setdefault(\"OTHER_FORECAST_DIR\", \"../slcosmo/other_forecast\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfad2a65",
      "metadata": {},
      "source": [
        "## 1. Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "998f5fac",
      "metadata": {},
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import corner\n",
        "import arviz as az\n",
        "\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import NUTS, MCMC\n",
        "from jax import random\n",
        "\n",
        "from slcosmo import SLCOSMO, SLmodel, tool\n",
        "\n",
        "TEST_MODE = os.environ.get(\"COMBINE_FORECAST_TEST\") == \"1\"\n",
        "DATA_DIR = os.environ.get(\"SLCOSMO_DATA_DIR\", os.path.join(\"..\", \"slcosmo\"))\n",
        "OTHER_FORECAST_DIR = os.environ.get(\"OTHER_FORECAST_DIR\", os.path.join(\"..\", \"SLCOSMO\", \"other_forecast\"))\n",
        "\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "numpyro.set_platform(\"gpu\")\n",
        "numpyro.enable_x64()\n",
        "\n",
        "slcosmo = SLCOSMO()\n",
        "model_instance = SLmodel(slcosmo)\n",
        "\n",
        "SEED = 42\n",
        "rng_np = np.random.default_rng(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9017af9",
      "metadata": {},
      "source": [
        "## 2. Cosmology model & priors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "54e0ae5a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosmology_model(kind, cosmo_prior, sample_h0=True):\n",
        "    cosmo = {\n",
        "        \"Omegam\": numpyro.sample(\"Omegam\", dist.Uniform(cosmo_prior[\"omegam_low\"], cosmo_prior[\"omegam_up\"])),\n",
        "        \"Omegak\": 0.0,\n",
        "        \"w0\": -1.0,\n",
        "        \"wa\": 0.0,\n",
        "        \"h0\": 70.0,\n",
        "    }\n",
        "    if kind in [\"wcdm\", \"owcdm\", \"waw0cdm\", \"owaw0cdm\"]:\n",
        "        cosmo[\"w0\"] = numpyro.sample(\"w0\", dist.Uniform(cosmo_prior[\"w0_low\"], cosmo_prior[\"w0_up\"]))\n",
        "    if kind in [\"waw0cdm\", \"owaw0cdm\"]:\n",
        "        cosmo[\"wa\"] = numpyro.sample(\"wa\", dist.Uniform(cosmo_prior[\"wa_low\"], cosmo_prior[\"wa_up\"]))\n",
        "    if kind in [\"owcdm\", \"owaw0cdm\"]:\n",
        "        cosmo[\"Omegak\"] = numpyro.sample(\"Omegak\", dist.Uniform(cosmo_prior[\"omegak_low\"], cosmo_prior[\"omegak_up\"]))\n",
        "    if sample_h0:\n",
        "        cosmo[\"h0\"] = numpyro.sample(\"h0\", dist.Uniform(cosmo_prior[\"h0_low\"], cosmo_prior[\"h0_up\"]))\n",
        "    return cosmo\n",
        "\n",
        "cosmo_prior = {\n",
        "    \"w0_up\": 0.0,   \"w0_low\": -2.0,\n",
        "    \"wa_up\": 2.0,   \"wa_low\": -2.0,\n",
        "    \"omegak_up\": 1.0, \"omegak_low\": -1.0,\n",
        "    \"h0_up\": 80.0,  \"h0_low\": 60.0,\n",
        "    \"omegam_up\": 0.5, \"omegam_low\": 0.1,\n",
        "}\n",
        "\n",
        "cosmo_true = {\"Omegam\": 0.32, \"Omegak\": 0.0, \"w0\": -1.0, \"wa\": 0.0, \"h0\": 70.0}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c69c1e69",
      "metadata": {},
      "source": [
        "## 3. DSPL mock data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62e51fa1",
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dspl = np.loadtxt(os.path.join(DATA_DIR, \"EuclidDSPLs_1.txt\"))\n",
        "data_dspl = data_dspl[(data_dspl[:, 5] < 0.95)]\n",
        "\n",
        "zl_dspl  = data_dspl[:, 0]\n",
        "zs1_dspl = data_dspl[:, 1]\n",
        "zs2_true_cat = data_dspl[:, 2]\n",
        "\n",
        "beta_err_dspl = data_dspl[:, 6]\n",
        "model_vel_dspl = data_dspl[:, 11]\n",
        "\n",
        "m_ok = (zs2_true_cat > zs1_dspl)\n",
        "zl_dspl  = zl_dspl[m_ok]\n",
        "zs1_dspl = zs1_dspl[m_ok]\n",
        "zs2_true_cat = zs2_true_cat[m_ok]\n",
        "beta_err_dspl = beta_err_dspl[m_ok]\n",
        "model_vel_dspl = model_vel_dspl[m_ok]\n",
        "\n",
        "N_dspl = len(zl_dspl)\n",
        "is_photo = (rng_np.random(N_dspl) < 0.60)\n",
        "zs2_err = np.where(is_photo, 0.1, 1e-4)\n",
        "zs2_obs = zs2_true_cat + rng_np.normal(0.0, zs2_err)\n",
        "\n",
        "eps = 1e-3\n",
        "bad = zs2_obs <= (zs1_dspl + eps)\n",
        "for _ in range(20):\n",
        "    if not np.any(bad):\n",
        "        break\n",
        "    zs2_obs[bad] = zs2_true_cat[bad] + rng_np.normal(0.0, zs2_err[bad])\n",
        "    bad = zs2_obs <= (zs1_dspl + eps)\n",
        "zs2_obs = np.maximum(zs2_obs, zs1_dspl + eps)\n",
        "\n",
        "Dl1, Ds1, Dls1 = tool.compute_distances(zl_dspl, zs1_dspl, cosmo_true)\n",
        "Dl2, Ds2, Dls2 = tool.compute_distances(zl_dspl, zs2_true_cat, cosmo_true)\n",
        "beta_geom_dspl = Dls1 * Ds2 / (Ds1 * Dls2)\n",
        "\n",
        "lambda_true_dspl = tool.truncated_normal(1.0, 0.05, 0.85, 1.15, N_dspl, random_state=rng_np)\n",
        "lambda_err_dspl = lambda_true_dspl * 0.06\n",
        "lambda_obs_dspl = lambda_true_dspl + np.random.normal(0.0, lambda_err_dspl)\n",
        "\n",
        "true_vel_dspl = model_vel_dspl * jnp.sqrt(lambda_true_dspl)\n",
        "vel_err_dspl = 0.03 * true_vel_dspl\n",
        "obs_vel_dspl = true_vel_dspl + np.random.normal(0.0, vel_err_dspl)\n",
        "\n",
        "beta_true_dspl = tool.beta_antimst(beta_geom_dspl, mst=lambda_true_dspl)\n",
        "beta_obs_dspl = tool.truncated_normal(beta_true_dspl, beta_err_dspl, 0.0, 1.0, random_state=rng_np)\n",
        "\n",
        "dspl_data = {\n",
        "    \"zl\": zl_dspl,\n",
        "    \"zs1\": zs1_dspl,\n",
        "    \"zs2_cat\": zs2_true_cat,\n",
        "    \"zs2_obs\": zs2_true_cat,\n",
        "    \"zs2_err\": zs2_err,\n",
        "    \"is_photo\": is_photo.astype(np.int32),\n",
        "    \"beta_obs\": beta_true_dspl,\n",
        "    \"beta_err\": beta_err_dspl,\n",
        "    \"v_model\": model_vel_dspl,\n",
        "    \"v_obs\": obs_vel_dspl,\n",
        "    \"v_err\": vel_err_dspl,\n",
        "    \"lambda_err\": lambda_err_dspl,\n",
        "    \"lambda_obs\": lambda_true_dspl,\n",
        "}\n",
        "\n",
        "photo_z = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23dfa1d5",
      "metadata": {},
      "source": [
        "## 4. Lens + kinematics mock data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "107e40d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "LUT = np.load(os.path.join(DATA_DIR, \"velocity_disp_table.npy\"))\n",
        "N1, N2, N3, N4 = LUT.shape\n",
        "thetaE_grid = np.linspace(0.5, 3.0, N1)\n",
        "gamma_grid  = np.linspace(1.2, 2.8, N2)\n",
        "Re_grid     = np.linspace(0.15, 3.0, N3)\n",
        "beta_grid   = np.linspace(-0.5, 0.8, N4)\n",
        "jampy_interp = tool.make_4d_interpolant(thetaE_grid, gamma_grid, Re_grid, beta_grid, LUT)\n",
        "\n",
        "Euclid_GG_data = np.loadtxt(os.path.join(DATA_DIR, \"Euclid_len.txt\"))\n",
        "zl_lens = Euclid_GG_data[:, 0]\n",
        "zs_lens = Euclid_GG_data[:, 1]\n",
        "Ein_lens = Euclid_GG_data[:, 2]\n",
        "re_lens = Euclid_GG_data[:, 5]\n",
        "\n",
        "mask_lens = (Ein_lens >= 0.6) & (re_lens >= 0.25) & (re_lens <= 2.8)\n",
        "zl_lens = zl_lens[mask_lens]\n",
        "zs_lens = zs_lens[mask_lens]\n",
        "thetaE_lens = Ein_lens[mask_lens]\n",
        "re_lens = re_lens[mask_lens]\n",
        "\n",
        "dl_lens, ds_lens, dls_lens = tool.dldsdls(zl_lens, zs_lens, cosmo_true, n=20)\n",
        "N_lens = len(zl_lens)\n",
        "\n",
        "gamma_true_lens = tool.truncated_normal(2.0, 0.2, 1.5, 2.5, N_lens, random_state=rng_np)\n",
        "beta_true_lens  = tool.truncated_normal(0.0, 0.2, -0.4, 0.4, N_lens, random_state=rng_np)\n",
        "vel_model_lens = jampy_interp(thetaE_lens, gamma_true_lens, re_lens, beta_true_lens) * jnp.sqrt(ds_lens / dls_lens)\n",
        "lambda_true_lens = tool.truncated_normal(1.0, 0.05, 0.8, 1.2, N_lens, random_state=rng_np)\n",
        "vel_true_lens = vel_model_lens * jnp.sqrt(lambda_true_lens)\n",
        "\n",
        "gamma_obs_lens = gamma_true_lens + tool.truncated_normal(0.0, 0.05, -0.2, 0.2, N_lens, random_state=rng_np)\n",
        "theta_E_err = 0.01 * thetaE_lens\n",
        "thetaE_lens_obs = thetaE_lens + np.random.normal(0.0, theta_E_err)\n",
        "vel_err_lens = 0.10 * vel_true_lens\n",
        "vel_obs_lens = np.random.normal(vel_true_lens, vel_err_lens)\n",
        "\n",
        "lens_data = {\n",
        "    \"zl\": zl_lens,\n",
        "    \"zs\": zs_lens,\n",
        "    \"theta_E\": thetaE_lens,\n",
        "    \"theta_E_err\": theta_E_err,\n",
        "    \"re\": re_lens,\n",
        "    \"gamma_obs\": gamma_true_lens,\n",
        "    \"vel_obs\": vel_true_lens,\n",
        "    \"vel_err\": vel_err_lens,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde095ae",
      "metadata": {},
      "source": [
        "## 5. Lensed SNe mock data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "006bd3e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% 3) Lensed SNe mock data (time-delay likelihood)\n",
        "sn_data = pd.read_csv(os.path.join(DATA_DIR, \"Euclid_150SNe.csv\"))\n",
        "sn_data = sn_data[(sn_data[\"tmax\"] >= 5) & (sn_data[\"tmax\"] <= 80)]\n",
        "sn_data = sn_data.nlargest(70, 'tmax')\n",
        "zl_sne = np.array(sn_data[\"zl\"])\n",
        "zs_sne = np.array(sn_data[\"z_host\"])\n",
        "t_delay_true_days = np.array(sn_data[\"tmax\"])\n",
        "\n",
        "Dl_sne, Ds_sne, Dls_sne = tool.dldsdls(zl_sne, zs_sne, cosmo_true, n=20)\n",
        "Ddt_geom_sne = (1.0 + zl_sne) * Dl_sne * Ds_sne / Dls_sne\n",
        "\n",
        "N_sne = len(zl_sne)\n",
        "# Parent population for MST (lambda)\n",
        "lambda_pop_mean = 1.0\n",
        "lambda_pop_sigma = 0.05\n",
        "lambda_low, lambda_high = 0.8, 1.2\n",
        "lambda_true_sne = tool.truncated_normal(lambda_pop_mean, lambda_pop_sigma, lambda_low, lambda_high, N_sne, random_state=rng_np)\n",
        "\n",
        "# Ddt inferred from cosmology (no direct measurement error)\n",
        "Ddt_true_sne = Ddt_geom_sne * lambda_true_sne\n",
        "\n",
        "seconds_per_day = 86400.0\n",
        "Mpc_km = tool.Mpc / 1000.0\n",
        "\n",
        "# Fermat potential difference from true time delay\n",
        "fermat_phi_true = (tool.c_km_s * t_delay_true_days * seconds_per_day) / (Ddt_true_sne * Mpc_km)\n",
        "\n",
        "# Measurement errors (assumed in likelihood)\n",
        "sigma_t_days = 1.0\n",
        "sigma_phi_frac = 0.05\n",
        "sigma_lambda_frac = 0.08\n",
        "\n",
        "# Observed quantities (NO noise in mock data)\n",
        "t_delay_obs = t_delay_true_days.copy()\n",
        "fermat_phi_obs = fermat_phi_true.copy()\n",
        "lambda_obs_sne = lambda_true_sne.copy()\n",
        "lambda_err_sne = sigma_lambda_frac * np.abs(lambda_obs_sne)\n",
        "\n",
        "def scale_phi(phi_obs):\n",
        "    finite = np.isfinite(phi_obs) & (phi_obs != 0)\n",
        "    if not np.any(finite):\n",
        "        return phi_obs, 1.0\n",
        "    median = np.median(np.abs(phi_obs[finite]))\n",
        "    if (not np.isfinite(median)) or median == 0:\n",
        "        return phi_obs, 1.0\n",
        "    exp = int(np.round(-np.log10(median)))\n",
        "    scale = 10.0 ** exp\n",
        "    return phi_obs * scale, scale\n",
        "\n",
        "fermat_phi_obs_scaled, phi_scale_sne = scale_phi(fermat_phi_obs)\n",
        "phi_scale_sne = np.full_like(fermat_phi_obs_scaled, phi_scale_sne, dtype=float)\n",
        "\n",
        "sne_data = {\n",
        "    \"zl\": zl_sne,\n",
        "    \"zs\": zs_sne,\n",
        "    \"t_obs\": t_delay_obs,\n",
        "    \"phi_obs\": fermat_phi_obs_scaled,\n",
        "    \"phi_scale\": phi_scale_sne,\n",
        "    \"lambda_obs\": lambda_obs_sne,\n",
        "    \"lambda_err\": lambda_err_sne,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a46504",
      "metadata": {},
      "source": [
        "## 6. Joint model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "bd14ca84",
      "metadata": {},
      "outputs": [],
      "source": [
        "def joint_model(dspl_data=None, lens_data=None, sne_data=None):\n",
        "    cosmo = cosmology_model(\"waw0cdm\", cosmo_prior, sample_h0=True)\n",
        "    lambda_mean = numpyro.sample(\"lambda_mean\", dist.Uniform(0.9, 1.1))\n",
        "    lambda_sigma = numpyro.sample(\"lambda_sig\", dist.TruncatedNormal(0.05, 0.5, low=0.0, high=0.2))\n",
        "\n",
        "    gamma_mean = numpyro.sample(\"gamma_mean\", dist.Uniform(1.8, 2.2))\n",
        "    gamma_sigma = numpyro.sample(\"gamma_sigma\", dist.TruncatedNormal(0.2, 0.5, low=0.0, high=0.4))\n",
        "    beta_mean  = numpyro.sample(\"beta_mean\", dist.Uniform(-0.1, 0.1))\n",
        "    beta_sigma = numpyro.sample(\"beta_sigma\", dist.TruncatedNormal(0.2, 0.5, low=0.0, high=0.4))\n",
        "\n",
        "    if dspl_data is not None:\n",
        "        N_dspl = len(dspl_data[\"zl\"])\n",
        "\n",
        "        zl  = jnp.asarray(dspl_data[\"zl\"])\n",
        "        zs1 = jnp.asarray(dspl_data[\"zs1\"])\n",
        "        zs2_obs = jnp.asarray(dspl_data[\"zs2_obs\"])\n",
        "        zs2_err = jnp.asarray(dspl_data[\"zs2_err\"])\n",
        "\n",
        "        Dl1, Ds1, Dls1 = tool.compute_distances(zl, zs1, cosmo)\n",
        "\n",
        "        if photo_z:\n",
        "            eps = 1e-3\n",
        "            zs2_true = numpyro.sample(\n",
        "                \"zs2_true\",\n",
        "                dist.TruncatedNormal(zs2_obs, zs2_err, low=zs1 + eps, high=10.0).to_event(1)\n",
        "            )\n",
        "        else:\n",
        "            zs2_true = dspl_data[\"zs2_cat\"]\n",
        "        Dl2, Ds2, Dls2 = tool.compute_distances(zl, zs2_true, cosmo)\n",
        "        beta_geom = Dls1 * Ds2 / (Ds1 * Dls2)\n",
        "\n",
        "        with numpyro.plate(\"dspl\", N_dspl):\n",
        "            lambda_dspl = numpyro.sample(\n",
        "                \"lambda_dspl\",\n",
        "                dist.TruncatedNormal(lambda_mean, lambda_sigma, low=0.8, high=1.2),\n",
        "            )\n",
        "            numpyro.sample(\n",
        "                \"lambda_dspl_like\",\n",
        "                dist.Normal(lambda_dspl, jnp.asarray(dspl_data[\"lambda_err\"])),\n",
        "                obs=jnp.asarray(dspl_data[\"lambda_obs\"]),\n",
        "            )\n",
        "            beta_mst = tool.beta_antimst(beta_geom, lambda_dspl)\n",
        "            numpyro.sample(\n",
        "                \"beta_dspl_like\",\n",
        "                dist.TruncatedNormal(beta_mst, jnp.asarray(dspl_data[\"beta_err\"]), low=0.0, high=1.0),\n",
        "                obs=jnp.asarray(dspl_data[\"beta_obs\"]),\n",
        "            )\n",
        "\n",
        "    if lens_data is not None:\n",
        "        dl_lens, ds_lens, dls_lens = tool.dldsdls(lens_data[\"zl\"], lens_data[\"zs\"], cosmo, n=20)\n",
        "        N_lens = len(lens_data[\"zl\"])\n",
        "        with numpyro.plate(\"lens\", N_lens):\n",
        "            gamma_i = numpyro.sample(\n",
        "                \"gamma_i\",\n",
        "                dist.TruncatedNormal(gamma_mean, gamma_sigma, low=1.6, high=2.4),\n",
        "            )\n",
        "            beta_i = numpyro.sample(\n",
        "                \"beta_i\",\n",
        "                dist.TruncatedNormal(beta_mean, beta_sigma, low=-0.4, high=0.4),\n",
        "            )\n",
        "            lambda_lens = numpyro.sample(\n",
        "                \"lambda_lens\",\n",
        "                dist.TruncatedNormal(lambda_mean, lambda_sigma, low=0.8, high=1.2),\n",
        "            )\n",
        "            theta_E_i = numpyro.sample(\n",
        "                \"theta_E_i\",\n",
        "                dist.Normal(lens_data[\"theta_E\"], lens_data[\"theta_E_err\"]),\n",
        "            )\n",
        "            v_interp = jampy_interp(theta_E_i, gamma_i, lens_data[\"re\"], beta_i)\n",
        "            vel_pred = v_interp * jnp.sqrt(ds_lens / dls_lens) * jnp.sqrt(lambda_lens)\n",
        "\n",
        "            numpyro.sample(\n",
        "                \"gamma_obs_lens\",\n",
        "                dist.Normal(gamma_i, 0.05),\n",
        "                obs=lens_data[\"gamma_obs\"],\n",
        "            )\n",
        "            numpyro.sample(\n",
        "                \"vel_lens_like\",\n",
        "                dist.Normal(vel_pred, lens_data[\"vel_err\"]),\n",
        "                obs=lens_data[\"vel_obs\"],\n",
        "            )\n",
        "\n",
        "    if sne_data is not None:\n",
        "        Dl_sne, Ds_sne, Dls_sne = tool.dldsdls(sne_data[\"zl\"], sne_data[\"zs\"], cosmo, n=20)\n",
        "        Ddt_geom = (1.0 + sne_data[\"zl\"]) * Dl_sne * Ds_sne / Dls_sne\n",
        "        N_sne = len(sne_data[\"zl\"])\n",
        "\n",
        "        t_obs = jnp.asarray(sne_data[\"t_obs\"])\n",
        "        phi_obs = jnp.asarray(sne_data[\"phi_obs\"])\n",
        "        phi_scale = jnp.asarray(sne_data[\"phi_scale\"])\n",
        "        lambda_obs = jnp.asarray(sne_data[\"lambda_obs\"])\n",
        "        lambda_err = jnp.asarray(sne_data[\"lambda_err\"])\n",
        "        sigma_phi = sigma_phi_frac * phi_obs\n",
        "\n",
        "        with numpyro.plate(\"sne\", N_sne):\n",
        "            phi_true_scaled = numpyro.sample(\"phi_true_scaled_sne\", dist.TruncatedNormal(phi_obs, sigma_phi, low=0.0, high=10.0))\n",
        "            lambda_sne = numpyro.sample(\"lambda_sne\", dist.TruncatedNormal(lambda_mean, lambda_sigma, low=0.8, high=1.2))\n",
        "            numpyro.sample(\n",
        "                \"lambda_sne_like\",\n",
        "                dist.Normal(lambda_sne, lambda_err),\n",
        "                obs=lambda_obs,\n",
        "            )\n",
        "\n",
        "            phi_true = phi_true_scaled / phi_scale\n",
        "            Ddt_true = Ddt_geom * lambda_sne\n",
        "            t_model_days = (Ddt_true * Mpc_km / tool.c_km_s) * phi_true / seconds_per_day\n",
        "            numpyro.sample(\n",
        "                \"t_delay_sne_like\",\n",
        "                dist.Normal(t_model_days, sigma_t_days),\n",
        "                obs=t_obs,\n",
        "            )\n",
        "\n",
        "def head_dict(data_dict, N_use=None):\n",
        "    return {k: np.asarray(v)[:N_use] for k, v in data_dict.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82e2e20e",
      "metadata": {},
      "source": [
        "## 7. Run MCMC (test-mode defaults)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "234615ed",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sample: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2000/2000 [1:06:11<00:00,  1.99s/it]\n"
          ]
        }
      ],
      "source": [
        "if TEST_MODE:\n",
        "    N_DSPL_USE = 50\n",
        "    N_LENS_USE = 200\n",
        "    N_SNE_USE = 10\n",
        "    num_warmup = 200\n",
        "    num_samples = 200\n",
        "    num_chains = 2\n",
        "    chain_method = \"sequential\"\n",
        "else:\n",
        "    N_DSPL_USE = 1200\n",
        "    N_LENS_USE = 5000\n",
        "    N_SNE_USE = 50\n",
        "    num_warmup = 500\n",
        "    num_samples = 1500\n",
        "    num_chains = 8\n",
        "    chain_method = \"vectorized\"\n",
        "\n",
        "dspl_data = head_dict(dspl_data, N_DSPL_USE)\n",
        "lens_data = head_dict(lens_data, N_LENS_USE)\n",
        "sne_data  = head_dict(sne_data,  N_SNE_USE)\n",
        "\n",
        "init_values = {\n",
        "    \"h0\": 70.0,\n",
        "    \"Omegam\": 0.32,\n",
        "    \"w0\": -1.0,\n",
        "    \"wa\": 0.0,\n",
        "    \"lambda_mean\": 1.0,\n",
        "    \"lambda_sig\": 0.05,\n",
        "    \"gamma_mean\": 2.0,\n",
        "    \"gamma_sigma\": 0.2,\n",
        "    \"beta_mean\": 0.0,\n",
        "    \"beta_sigma\": 0.2,\n",
        "}\n",
        "\n",
        "from numpyro.infer import init_to_value\n",
        "init_strategy = init_to_value(values=init_values)\n",
        "\n",
        "nuts_kernel = NUTS(\n",
        "    joint_model,\n",
        "    target_accept_prob=0.8,\n",
        "    dense_mass=[(\"wa\", \"w0\", \"h0\", \"Omegam\", \"lambda_mean\")],\n",
        "    init_strategy=init_strategy,\n",
        ")\n",
        "mcmc = MCMC(\n",
        "    nuts_kernel,\n",
        "    num_warmup=num_warmup,\n",
        "    num_samples=num_samples,\n",
        "    num_chains=num_chains,\n",
        "    chain_method=chain_method,\n",
        "    progress_bar=True,\n",
        ")\n",
        "\n",
        "rng_key = random.PRNGKey(0)\n",
        "mcmc.run(rng_key, dspl_data=dspl_data, sne_data=sne_data, lens_data=lens_data)\n",
        "\n",
        "posterior = jax.device_get(mcmc.get_samples(group_by_chain=True))\n",
        "sample_stats = jax.device_get(mcmc.get_extra_fields(group_by_chain=True))\n",
        "inf_data = az.from_dict(posterior=posterior, sample_stats=sample_stats)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "19de636f-5f9c-4e8f-be77-37ae151ee5a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: result/Lens_revolution_summary.csv\n",
            "Saved: result/Lens_revolution.nc\n"
          ]
        }
      ],
      "source": [
        "nc_filename = \"result/Lens_revolution\"\n",
        "summary_df = az.summary(\n",
        "    inf_data,\n",
        "    var_names=[\"wa\", \"w0\", \"h0\", \"Omegam\"],round_to=4\n",
        ")\n",
        "summary_df.to_csv(nc_filename + \"_summary.csv\")\n",
        "az.to_netcdf(inf_data, nc_filename + \".nc\")\n",
        "\n",
        "print(\"Saved:\", nc_filename + \"_summary.csv\")\n",
        "print(\"Saved:\", nc_filename + \".nc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef39217b",
      "metadata": {},
      "source": [
        "## 8. Plots and comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9449eaf7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed no burn in\n",
            "Removed no burn in\n",
            "Removed no burn in\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "from getdist import plots, MCSamples\n",
        "corner_vars = [\n",
        "    \"h0\", \"Omegam\", \"w0\", \"wa\",\n",
        "    \"gamma_mean\", \"gamma_sigma\",\n",
        "    \"beta_mean\", \"beta_sigma\",\n",
        "    \"lambda_mean\", \"lambda_sig\",\n",
        "]\n",
        "truths = [70, 0.32, -1.0, 0.0, 2.0, 0.2, 0.0, 0.2, 1.0, 0.05]\n",
        "\n",
        "fig = corner.corner(inf_data, truths=truths, var_names=corner_vars, show_title=True)\n",
        "fig.savefig(nc_filename + \".pdf\")\n",
        "plt.close(fig)\n",
        "\n",
        "# ============================\n",
        "# 1. Read three w0, wa samples\n",
        "# ============================\n",
        "posterior_supernovae = pd.DataFrame(\n",
        "    np.genfromtxt(os.path.join(OTHER_FORECAST_DIR, \"Y10_SN.txt\")),\n",
        "    columns=[\"Omega_m\", \"sigma_8\", \"n_s\", \"w_0\", \"w_a\", \"Omega_b\", \"H_0\"],\n",
        ")\n",
        "samples_supernovae = posterior_supernovae[[\"w_0\", \"w_a\"]].to_numpy()\n",
        "\n",
        "param_names_all = [\n",
        "    \"Omegam\", \"Omegab\", \"w0\", \"wa\", \"h\", \"ns\", \"sigma8\",\n",
        "    \"aIA\", \"etaIA\", \"betaIA\", \"b1\", \"b2\", \"b3\", \"b4\", \"b5\",\n",
        "    \"b6\", \"b7\", \"b8\", \"b9\", \"b10\",\n",
        "]\n",
        "\n",
        "fisher_matrix = np.genfromtxt(os.path.join(OTHER_FORECAST_DIR, \"EuclidISTF_WL_w0wa_flat_pessimistic.txt\"))\n",
        "covariance_matrix = np.linalg.inv(fisher_matrix)\n",
        "\n",
        "idx_w0 = param_names_all.index(\"w0\")\n",
        "idx_wa = param_names_all.index(\"wa\")\n",
        "cov_sub = covariance_matrix[np.ix_([idx_w0, idx_wa], [idx_w0, idx_wa])]\n",
        "\n",
        "mean_w0 = -1.0\n",
        "mean_wa = 0.0\n",
        "mean = [mean_w0, mean_wa]\n",
        "\n",
        "num_samples = 10000\n",
        "samples_Euclid = np.random.multivariate_normal(mean, cov_sub, size=num_samples)\n",
        "\n",
        "idata = az.from_netcdf(nc_filename + \".nc\")\n",
        "w0_joint = idata.posterior[\"w0\"].values.reshape(-1)\n",
        "wa_joint = idata.posterior[\"wa\"].values.reshape(-1)\n",
        "w0_joint = w0_joint - np.mean(w0_joint) - 1\n",
        "wa_joint = wa_joint - np.mean(wa_joint)\n",
        "samples_joint = np.vstack([w0_joint, wa_joint]).T\n",
        "\n",
        "# ============================\n",
        "# 2. Convert to GetDist\n",
        "# ============================\n",
        "\n",
        "names = [\"w0\", \"wa\"]\n",
        "labels = [r\"w_0\", r\"w_a\"]\n",
        "\n",
        "mc_sne = MCSamples(\n",
        "    samples=samples_supernovae,\n",
        "    names=names,\n",
        "    labels=labels,\n",
        "    settings={\"smooth_scale_2D\": 0.5},\n",
        ")\n",
        "\n",
        "mc_euclid = MCSamples(\n",
        "    samples=samples_Euclid,\n",
        "    names=names,\n",
        "    labels=labels,\n",
        ")\n",
        "\n",
        "mc_joint = MCSamples(\n",
        "    samples=samples_joint,\n",
        "    names=names,\n",
        "    labels=labels,\n",
        "    settings={\"smooth_scale_2D\": 0.5},\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# 3. GetDist 2D plot\n",
        "# ============================\n",
        "\n",
        "g = plots.get_subplot_plotter(subplot_size=5)\n",
        "\n",
        "g.plot_2d(\n",
        "    [mc_sne, mc_euclid, mc_joint],\n",
        "    param_pair=(\"w0\", \"wa\"),\n",
        "    filled=[True, True, True],\n",
        "    line_args=[\n",
        "        {\"ls\": \"--\", \"alpha\": 0.7, \"lw\": 2},\n",
        "        {\"ls\": \"--\", \"alpha\": 0.7, \"lw\": 2},\n",
        "        {\"ls\": \"-\", \"lw\": 2},\n",
        "    ],\n",
        "    colors=[\"orange\", \"green\", \"black\"],\n",
        ")\n",
        "\n",
        "g.add_legend(\n",
        "    [\"LSST SNe\", \"Euclid Weak Lensing\", \"Strong Lensing Y10\"],\n",
        "    frameon=True,\n",
        "    framealpha=0.8,\n",
        "    edgecolor=\"black\",\n",
        "    facecolor=\"white\",\n",
        "    fontsize=10,\n",
        "    legend_loc=\"upper left\",\n",
        ")\n",
        "\n",
        "g.export(nc_filename + \"compare.pdf\")\n",
        "plt.close(g.fig)\n",
        "del g\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb48a581-43b4-4fd7-9a5f-0432d833cd54",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Herculens_Tian",
      "language": "python",
      "name": "herculens_tian"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}