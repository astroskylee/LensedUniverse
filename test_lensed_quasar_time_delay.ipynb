{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a37c39aa",
   "metadata": {},
   "source": [
    "# Quasar time-delay cosmology inference (from static datavectors)\n",
    "\n",
    "This notebook mirrors `test_sne_forecast_time_delay.ipynb` and uses **only** redshifts + time delays\n",
    "from `static_datavectors_seed6.json`. We infer Fermat potential differences from time delays using a\n",
    "fiducial cosmology, then run cosmology inference with MST.\n",
    "\n",
    "Assumptions:\n",
    "- Inputs: `z_lens`, `z_src`, `td_measured` only.\n",
    "- If a block has 3 time delays, we keep the **largest |time delay|** per lens.\n",
    "- Time-delay errors: blocks 0–2 use 3% fractional; others use 5 days absolute.\n",
    "- Fermat potential errors are block-dependent (set in `phi_err_frac_by_block`).\n",
    "- MST is always included. Sigma_v errors map to lambda errors via sigma_v ∝ sqrt(lambda_int),\n",
    "  so fractional lambda error = 2 * fractional sigma_v error.\n",
    "- Blocks 7–8 have no sigma_v; their MST error uses the parent population sigma.\n",
    "- Two modes: noisy observations vs. noiseless observations with likelihood noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "workdir = Path.cwd()\n",
    "if (workdir / \"LensedUniverse\").is_dir():\n",
    "    workdir = workdir / \"LensedUniverse\"\n",
    "os.chdir(workdir)\n",
    "sys.path.insert(0, str(workdir))\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "\n",
    "from slcosmo.tools import tool\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "numpyro.enable_x64()\n",
    "\n",
    "if any(d.platform == \"gpu\" for d in jax.devices()):\n",
    "    numpyro.set_platform(\"gpu\")\n",
    "else:\n",
    "    numpyro.set_platform(\"cpu\")\n",
    "\n",
    "print(\"JAX devices:\", jax.devices())\n",
    "print(\"JAX default backend:\", jax.default_backend())\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8956a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Load redshifts + time delays from JSON\n",
    "# ---------------------------\n",
    "DATA_JSON = Path(\"../Temp_data/static_datavectors_seed6.json\")\n",
    "with DATA_JSON.open(\"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "z_lens_list = []\n",
    "z_src_list = []\n",
    "t_base_list = []\n",
    "t_err_list = []\n",
    "block_id_list = []\n",
    "lens_id_list = []\n",
    "pair_id_list = []\n",
    "\n",
    "for b, block in enumerate(data):\n",
    "    z_lens = np.asarray(block[\"z_lens\"], dtype=float)\n",
    "    z_src = np.asarray(block[\"z_src\"], dtype=float)\n",
    "\n",
    "    td = np.asarray(block[\"td_measured\"], dtype=float)\n",
    "    td_mean = td.mean(axis=1)  # (n_lens, n_td)\n",
    "\n",
    "    n_lens, n_td = td_mean.shape\n",
    "\n",
    "    if n_td == 3:\n",
    "        idx = np.argmax(np.abs(td_mean), axis=1)\n",
    "        t_base = np.abs(td_mean[np.arange(n_lens), idx])\n",
    "        pair_id = idx\n",
    "    else:\n",
    "        t_base = np.abs(td_mean[:, 0])\n",
    "        pair_id = np.zeros(n_lens, dtype=int)\n",
    "\n",
    "    if b in (0, 1, 2):\n",
    "        t_err = 0.03 * t_base\n",
    "    else:\n",
    "        t_err = np.full_like(t_base, 5.0)\n",
    "\n",
    "    z_lens_list.append(z_lens)\n",
    "    z_src_list.append(z_src)\n",
    "    t_base_list.append(t_base)\n",
    "    t_err_list.append(t_err)\n",
    "    block_id_list.append(np.full(n_lens, b, dtype=int))\n",
    "    lens_id_list.append(np.arange(n_lens, dtype=int))\n",
    "    pair_id_list.append(pair_id)\n",
    "\n",
    "z_lens = np.concatenate(z_lens_list)\n",
    "z_src = np.concatenate(z_src_list)\n",
    "t_base = np.concatenate(t_base_list)\n",
    "t_err = np.concatenate(t_err_list)\n",
    "block_id = np.concatenate(block_id_list)\n",
    "lens_id = np.concatenate(lens_id_list)\n",
    "pair_id = np.concatenate(pair_id_list)\n",
    "\n",
    "print(\"Total lenses used (1 td per lens):\", z_lens.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Fiducial cosmology and Fermat potential from time delays\n",
    "# ---------------------------\n",
    "cosmo_true = {\"Omegam\": 0.32, \"Omegak\": 0.0, \"w0\": -1.0, \"wa\": 0.0, \"h0\": 70.0}\n",
    "\n",
    "zl_j = jnp.asarray(z_lens)\n",
    "zs_j = jnp.asarray(z_src)\n",
    "Dl, Ds, Dls = tool.dldsdls(zl_j, zs_j, cosmo_true, n=20)\n",
    "Ddt_geom = (1.0 + zl_j) * Dl * Ds / Dls\n",
    "Ddt_geom = np.asarray(Ddt_geom)\n",
    "\n",
    "c_km_day = tool.c_km_s * 86400.0\n",
    "Mpc_km = tool.Mpc / 1000.0\n",
    "\n",
    "phi_true = (c_km_day * t_base) / (Ddt_geom * Mpc_km)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619fbe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# MST + measurement model configuration\n",
    "# ---------------------------\n",
    "USE_NOISY_OBS = False\n",
    "\n",
    "lambda_pop_mean = 1.0\n",
    "lambda_pop_sigma = 0.05\n",
    "lambda_low, lambda_high = 0.8, 1.2\n",
    "\n",
    "phi_err_frac_by_block = {\n",
    "    0: 0.02,\n",
    "    1: 0.05,\n",
    "    2: 0.05,\n",
    "    3: 0.11,\n",
    "    4: 0.11,\n",
    "    5: 0.18,\n",
    "    6: 0.18,\n",
    "    7: 0.18,\n",
    "    8: 0.18,\n",
    "}\n",
    "\n",
    "sigma_v_frac_by_block = {\n",
    "    0: 0.03,\n",
    "    1: 0.03,\n",
    "    2: 0.03,\n",
    "    3: 0.10,\n",
    "    4: 0.10,\n",
    "    5: 0.10,\n",
    "    6: 0.10,\n",
    "    7: np.nan,\n",
    "    8: np.nan,\n",
    "}\n",
    "\n",
    "mst_mask = np.isfinite(np.asarray([sigma_v_frac_by_block[b] for b in block_id]))\n",
    "\n",
    "\n",
    "phi_err_frac = np.asarray([phi_err_frac_by_block[b] for b in block_id])\n",
    "phi_err = phi_err_frac * np.abs(phi_true)\n",
    "\n",
    "lambda_true = tool.truncated_normal(\n",
    "    lambda_pop_mean,\n",
    "    lambda_pop_sigma,\n",
    "    lambda_low,\n",
    "    lambda_high,\n",
    "    z_lens.size,\n",
    "    random_state=rng,\n",
    ")\n",
    "\n",
    "sigma_v_frac = np.asarray([sigma_v_frac_by_block[b] for b in block_id])\n",
    "mst_err_frac = 2.0 * sigma_v_frac\n",
    "\n",
    "lambda_err = np.where(\n",
    "    np.isfinite(mst_err_frac),\n",
    "    mst_err_frac * np.abs(lambda_true),\n",
    "    lambda_pop_sigma,\n",
    ")\n",
    "\n",
    "# MST always applied\n",
    "t_true = t_base * lambda_true\n",
    "\n",
    "# Observations: clean vs noisy\n",
    "\n",
    "t_obs_clean = t_true.copy()\n",
    "phi_obs_clean = phi_true.copy()\n",
    "lambda_obs_clean = lambda_true.copy()\n",
    "\n",
    "t_obs_noisy = t_true + rng.normal(0.0, t_err)\n",
    "phi_obs_noisy = phi_true + rng.normal(0.0, phi_err)\n",
    "lambda_obs_noisy = lambda_true + rng.normal(0.0, lambda_err)\n",
    "\n",
    "# Scale Fermat potentials for stability\n",
    "\n",
    "def scale_phi(phi_in):\n",
    "    finite = np.isfinite(phi_in) & (phi_in != 0)\n",
    "    if not np.any(finite):\n",
    "        return phi_in, 1.0\n",
    "    median = np.median(np.abs(phi_in[finite]))\n",
    "    if (not np.isfinite(median)) or median == 0:\n",
    "        return phi_in, 1.0\n",
    "    exp = int(np.round(-np.log10(median)))\n",
    "    scale = 10.0 ** exp\n",
    "    return phi_in * scale, scale\n",
    "\n",
    "phi_true_scaled, phi_scale = scale_phi(phi_true)\n",
    "phi_obs_clean_scaled = phi_obs_clean * phi_scale\n",
    "phi_obs_noisy_scaled = phi_obs_noisy * phi_scale\n",
    "phi_err_scaled = phi_err_frac * np.abs(phi_true_scaled)\n",
    "\n",
    "print(\"phi_scale:\", phi_scale)\n",
    "print(\"phi_obs scaled median:\", np.median(np.abs(phi_true_scaled)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96871f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import NUTS, MCMC\n",
    "from jax import random\n",
    "\n",
    "cosmo_prior = {\n",
    "    \"w0_up\": 0.0,\n",
    "    \"w0_low\": -2.0,\n",
    "    \"wa_up\": 2.0,\n",
    "    \"wa_low\": -2.0,\n",
    "    \"omegak_up\": 1.0,\n",
    "    \"omegak_low\": -1.0,\n",
    "    \"h0_up\": 80.0,\n",
    "    \"h0_low\": 60.0,\n",
    "    \"omegam_up\": 0.5,\n",
    "    \"omegam_low\": 0.1,\n",
    "}\n",
    "\n",
    "\n",
    "def cosmology_model(kind, cosmo_prior, sample_h0=True):\n",
    "    cosmo = {\n",
    "        \"Omegam\": numpyro.sample(\"Omegam\", dist.Uniform(cosmo_prior[\"omegam_low\"], cosmo_prior[\"omegam_up\"])),\n",
    "        \"Omegak\": 0.0,\n",
    "        \"w0\": -1.0,\n",
    "        \"wa\": 0.0,\n",
    "        \"h0\": 70.0,\n",
    "    }\n",
    "    if kind in [\"wcdm\", \"owcdm\", \"waw0cdm\", \"owaw0cdm\"]:\n",
    "        cosmo[\"w0\"] = numpyro.sample(\"w0\", dist.Uniform(cosmo_prior[\"w0_low\"], cosmo_prior[\"w0_up\"]))\n",
    "    if kind in [\"waw0cdm\", \"owaw0cdm\"]:\n",
    "        cosmo[\"wa\"] = numpyro.sample(\"wa\", dist.Uniform(cosmo_prior[\"wa_low\"], cosmo_prior[\"wa_up\"]))\n",
    "    if kind in [\"owcdm\", \"owaw0cdm\"]:\n",
    "        cosmo[\"Omegak\"] = numpyro.sample(\"Omegak\", dist.Uniform(cosmo_prior[\"omegak_low\"], cosmo_prior[\"omegak_up\"]))\n",
    "    if sample_h0:\n",
    "        cosmo[\"h0\"] = numpyro.sample(\"h0\", dist.Uniform(cosmo_prior[\"h0_low\"], cosmo_prior[\"h0_up\"]))\n",
    "    return cosmo\n",
    "\n",
    "\n",
    "def quasar_td_model(zl, zs, t_obs, t_err, phi_obs, phi_err, phi_scale, lambda_obs, lambda_err, mst_mask):\n",
    "    cosmo = cosmology_model(\"waw0cdm\", cosmo_prior, sample_h0=True)\n",
    "\n",
    "    zl = jnp.asarray(zl)\n",
    "    zs = jnp.asarray(zs)\n",
    "    t_obs = jnp.asarray(t_obs)\n",
    "    t_err = jnp.asarray(t_err)\n",
    "    phi_obs = jnp.asarray(phi_obs)\n",
    "    phi_err = jnp.asarray(phi_err)\n",
    "    phi_scale = jnp.asarray(phi_scale)\n",
    "    lambda_obs = jnp.asarray(lambda_obs)\n",
    "    lambda_err = jnp.asarray(lambda_err)\n",
    "    mst_mask = jnp.asarray(mst_mask)\n",
    "\n",
    "    lambda_mean = numpyro.sample(\"lambda_mean\", dist.Uniform(0.9, 1.1))\n",
    "    lambda_sig = numpyro.sample(\"lambda_sig\", dist.TruncatedNormal(0.05, 0.5, low=0.0, high=0.2))\n",
    "    with numpyro.plate(\"lens\", zl.shape[0]):\n",
    "        lambda_true = numpyro.sample(\n",
    "            \"lambda_true\",\n",
    "            dist.TruncatedNormal(lambda_mean, lambda_sig, low=0.8, high=1.2),\n",
    "        )\n",
    "        numpyro.sample(\"lambda_like\", dist.Normal(lambda_true, lambda_err).mask(mst_mask), obs=lambda_obs)\n",
    "\n",
    "    Dl, Ds, Dls = tool.dldsdls(zl, zs, cosmo, n=20)\n",
    "    Ddt_geom = (1.0 + zl) * Dl * Ds / Dls\n",
    "\n",
    "    with numpyro.plate(\"td_obs\", zl.shape[0]):\n",
    "        phi_true_scaled = numpyro.sample(\"phi_true_scaled\", dist.Normal(phi_obs, phi_err))\n",
    "        phi_true = phi_true_scaled / phi_scale\n",
    "        t_model_days = (Ddt_geom * Mpc_km / c_km_day) * phi_true\n",
    "        t_model_days = t_model_days * lambda_true\n",
    "        numpyro.sample(\"t_delay_like\", dist.Normal(t_model_days, t_err), obs=t_obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Run MCMC (optional)\n",
    "# ---------------------------\n",
    "RUN_MCMC = True\n",
    "\n",
    "z_lens_s = z_lens\n",
    "z_src_s = z_src\n",
    "\n",
    "clean_data = {\n",
    "    \"t_obs\": t_obs_clean,\n",
    "    \"t_err\": t_err,\n",
    "    \"phi_obs\": phi_obs_clean_scaled,\n",
    "    \"phi_err\": phi_err_scaled,\n",
    "    \"phi_scale\": phi_scale,\n",
    "    \"lambda_obs\": lambda_obs_clean,\n",
    "    \"lambda_err\": lambda_err,\n",
    "}\n",
    "\n",
    "noisy_data = {\n",
    "    \"t_obs\": t_obs_noisy,\n",
    "    \"t_err\": t_err,\n",
    "    \"phi_obs\": phi_obs_noisy_scaled,\n",
    "    \"phi_err\": phi_err_scaled,\n",
    "    \"phi_scale\": phi_scale,\n",
    "    \"lambda_obs\": lambda_obs_noisy,\n",
    "    \"lambda_err\": lambda_err,\n",
    "}\n",
    "\n",
    "if RUN_MCMC:\n",
    "    import arviz as az\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    FIG_DIR = Path(\"result\")\n",
    "    FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def run_mcmc(data, key, tag):\n",
    "        nuts = NUTS(quasar_td_model, target_accept_prob=0.85)\n",
    "        mcmc = MCMC(nuts, num_warmup=500, num_samples=1000, num_chains=4, chain_method=\"vectorized\")\n",
    "        mcmc.run(\n",
    "            key,\n",
    "            zl=z_lens_s,\n",
    "            zs=z_src_s,\n",
    "            t_obs=data[\"t_obs\"],\n",
    "            t_err=data[\"t_err\"],\n",
    "            phi_obs=data[\"phi_obs\"],\n",
    "            phi_err=data[\"phi_err\"],\n",
    "            phi_scale=data[\"phi_scale\"],\n",
    "            lambda_obs=data[\"lambda_obs\"],\n",
    "            lambda_err=data[\"lambda_err\"],\n",
    "            mst_mask=mst_mask,\n",
    "        )\n",
    "        posterior = mcmc.get_samples(group_by_chain=True)\n",
    "        inf_data = az.from_dict(posterior=posterior)\n",
    "\n",
    "        extra = mcmc.get_extra_fields(group_by_chain=True)\n",
    "        n_div = int(np.asarray(extra[\"diverging\"]).sum())\n",
    "        print(f\"[{tag}] divergences: {n_div}\")\n",
    "\n",
    "        trace_vars = [\"h0\", \"Omegam\", \"w0\", \"wa\", \"lambda_mean\", \"lambda_sig\"]\n",
    "        trace_vars = [v for v in trace_vars if v in inf_data.posterior and inf_data.posterior[v].ndim == 2]\n",
    "        if trace_vars:\n",
    "            trace_axes = az.plot_trace(inf_data, var_names=trace_vars, compact=False)\n",
    "            trace_fig = np.asarray(trace_axes).ravel()[0].figure\n",
    "            trace_fig.savefig(FIG_DIR / f\"test_quasar_trace_{tag}.png\", dpi=200, bbox_inches=\"tight\")\n",
    "            plt.close(trace_fig)\n",
    "        return mcmc, inf_data, n_div\n",
    "\n",
    "    key = random.PRNGKey(42)\n",
    "    key_clean, key_noisy = random.split(key)\n",
    "\n",
    "    mcmc_clean, inf_data_clean, n_div_clean = run_mcmc(clean_data, key_clean, \"clean\")\n",
    "    mcmc_noisy, inf_data_noisy, n_div_noisy = run_mcmc(noisy_data, key_noisy, \"noisy\")\n",
    "\n",
    "    var_names = [\"h0\", \"Omegam\", \"w0\", \"wa\", \"lambda_mean\", \"lambda_sig\"]\n",
    "    print(\"Noiseless summary:\")\n",
    "    print(az.summary(inf_data_clean, var_names=var_names))\n",
    "    print(\"Noisy summary:\")\n",
    "    print(az.summary(inf_data_noisy, var_names=var_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Plotting (optional)\n",
    "# ---------------------------\n",
    "if RUN_MCMC:\n",
    "    import arviz as az\n",
    "    import matplotlib.pyplot as plt\n",
    "    import corner\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    FIG_DIR = Path(\"result\")\n",
    "    FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    plot_clean = inf_data_clean.isel(chain=[0, 1, 2, 3])\n",
    "    plot_noisy = inf_data_noisy.isel(chain=[0, 1, 2, 3])\n",
    "\n",
    "    df_clean = az.extract(plot_clean, var_names=var_names).to_dataframe()\n",
    "    df_noisy = az.extract(plot_noisy, var_names=var_names).to_dataframe()\n",
    "\n",
    "    fig = corner.corner(df_clean, labels=var_names, color=\"C0\")\n",
    "    corner.corner(df_noisy, labels=var_names, color=\"C1\", fig=fig)\n",
    "\n",
    "    handles = [\n",
    "        mpatches.Patch(color=\"C0\", label=\"noiseless\"),\n",
    "        mpatches.Patch(color=\"C1\", label=\"noisy\"),\n",
    "    ]\n",
    "    plt.legend(handles=handles, loc=\"upper right\")\n",
    "    fig.savefig(FIG_DIR / \"test_quasar_corner_overlay.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
