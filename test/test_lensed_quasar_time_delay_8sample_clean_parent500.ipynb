{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_lensed_quasar_time_delay_8sample_clean_parent500\n",
    "\n",
    "Clean-only 8-lens quasar time-delay forecast from `data/test_data.py`.\n",
    "\n",
    "Key logic:\n",
    "- Use only the longest time-delay pair (`max |dt|`) for each target.\n",
    "- LambdaCDM inference samples only `Omegam` and `H0` for cosmology.\n",
    "- MST truth is generated from population:\n",
    "  - `lambda_mean_true=1.0`\n",
    "  - `lambda_sigma_true=0.04`\n",
    "- Per-lens external convergence is included:\n",
    "  - `kext_true ~ N(0, 0.01)`\n",
    "  - `kext_err = 0.01`\n",
    "  - `lambda_eff = (1-kext)*lambda`\n",
    "- FPD is inferred from time-delay relation and uses 3% measurement error.\n",
    "- No noisy data mode: all runs use clean observations.\n",
    "\n",
    "Three inference scenarios:\n",
    "1) `fiducial_tdcosmo`: use individual MST measurements from kinematic-driven error budget.\n",
    "2) `individual_mst_8pct`: use individual MST measurements with additional +8% MST error added in quadrature.\n",
    "3) `parent500_no_individual`: no individual MST measurements, but add 500 parent-population MST observations, each with 1% constraint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import NUTS, MCMC, init_to_value\n",
    "from jax import random\n",
    "import arviz as az\n",
    "from corner import corner\n",
    "\n",
    "os.environ.setdefault('HDF5_USE_FILE_LOCKING', 'FALSE')\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_root = None\n",
    "\n",
    "if (cwd / 'slcosmo').is_dir() and (cwd / 'data').is_dir():\n",
    "    repo_root = cwd\n",
    "elif (cwd / 'LensedUniverse' / 'slcosmo').is_dir():\n",
    "    repo_root = cwd / 'LensedUniverse'\n",
    "else:\n",
    "    for candidate in [cwd, *cwd.parents]:\n",
    "        if (candidate / 'slcosmo').is_dir() and (candidate / 'data').is_dir():\n",
    "            repo_root = candidate\n",
    "            break\n",
    "\n",
    "if repo_root is None:\n",
    "    raise RuntimeError(f'Cannot locate LensedUniverse repo root from cwd={cwd}')\n",
    "\n",
    "workdir = repo_root\n",
    "os.chdir(workdir)\n",
    "if str(workdir) not in sys.path:\n",
    "    sys.path.insert(0, str(workdir))\n",
    "\n",
    "from slcosmo.tools import tool\n",
    "\n",
    "USE_X64 = os.environ.get('SLCOSMO_USE_X64', '0').strip().lower() in {'1', 'true', 'yes', 'y', 'on'}\n",
    "jax.config.update('jax_enable_x64', USE_X64)\n",
    "if USE_X64:\n",
    "    numpyro.enable_x64()\n",
    "if any(d.platform == 'gpu' for d in jax.devices()):\n",
    "    numpyro.set_platform('gpu')\n",
    "else:\n",
    "    numpyro.set_platform('cpu')\n",
    "\n",
    "print('Precision mode:', 'FP64' if USE_X64 else 'FP32')\n",
    "print('Repo root:', workdir)\n",
    "print('JAX devices:', jax.devices())\n",
    "\n",
    "SEED = 42\n",
    "rng_np = np.random.default_rng(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULT_DIR = workdir / 'test'\n",
    "RESULT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Load 8-lens dataset and keep only the longest delay pair per target\n",
    "# ---------------------------\n",
    "data_path = workdir / 'data' / 'test_data.py'\n",
    "spec = importlib.util.spec_from_file_location('test_data', data_path)\n",
    "test_data = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(test_data)\n",
    "tdcosmo_8lens = test_data.tdcosmo_8lens\n",
    "\n",
    "lens_names = sorted(tdcosmo_8lens.keys())\n",
    "\n",
    "z_lens = []\n",
    "z_src = []\n",
    "sigma_v = []\n",
    "sigma_v_err = []\n",
    "\n",
    "pair_name = []\n",
    "t_base = []\n",
    "t_err = []\n",
    "\n",
    "for name in lens_names:\n",
    "    d = tdcosmo_8lens[name]\n",
    "    z_lens.append(float(d['zl']))\n",
    "    z_src.append(float(d['zs']))\n",
    "    sigma_v.append(float(d['sigma_ap_los_kms']))\n",
    "    sigma_v_err.append(float(d['sigma_ap_los_err_kms']))\n",
    "\n",
    "    td_dict = d['time_delays_days']\n",
    "    p_long = max(td_dict, key=lambda p: abs(float(td_dict[p]['dt'])))\n",
    "    pair_name.append(f'{name}:{p_long}')\n",
    "    dt_val = float(td_dict[p_long]['dt'])\n",
    "    de = 0.5 * (float(td_dict[p_long].get('err_minus', 0.0)) + float(td_dict[p_long].get('err_plus', 0.0)))\n",
    "    t_base.append(abs(dt_val))\n",
    "    t_err.append(de)\n",
    "\n",
    "z_lens = np.asarray(z_lens, dtype=float)\n",
    "z_src = np.asarray(z_src, dtype=float)\n",
    "sigma_v = np.asarray(sigma_v, dtype=float)\n",
    "sigma_v_err = np.asarray(sigma_v_err, dtype=float)\n",
    "\n",
    "t_base = np.asarray(t_base, dtype=float)\n",
    "t_err = np.asarray(t_err, dtype=float)\n",
    "\n",
    "n_lens = z_lens.size\n",
    "n_obs = t_base.size\n",
    "\n",
    "print('N lens:', n_lens)\n",
    "print('N time-delay observations (longest pair only):', n_obs)\n",
    "for i, name in enumerate(lens_names):\n",
    "    print(f'  {i:02d} {name:15s} pair={pair_name[i]} sigma_v={sigma_v[i]:.1f}+-{sigma_v_err[i]:.1f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Build mock truth and clean observations\n",
    "# ---------------------------\n",
    "cosmo_true = {'Omegam': 0.3, 'Omegak': 0.0, 'w0': -1.0, 'wa': 0.0, 'h0': 70.0}\n",
    "\n",
    "Dl, Ds, Dls = tool.dldsdls(jnp.asarray(z_lens), jnp.asarray(z_src), cosmo_true, n=20)\n",
    "Ddt_lens = np.asarray((1.0 + z_lens) * Dl * Ds / Dls)\n",
    "Ddt_obs = Ddt_lens\n",
    "\n",
    "c_km_day = tool.c_km_s * 86400.0\n",
    "Mpc_km = tool.Mpc / 1000.0\n",
    "\n",
    "# Fixed MST population truth used to generate mock data\n",
    "lambda_mean_true = 1.0\n",
    "lambda_sigma_true = 0.04\n",
    "lambda_low_model = 0.6\n",
    "lambda_high_model = 1.6\n",
    "lambda_true_raw = tool.truncated_normal(\n",
    "    lambda_mean_true,\n",
    "    lambda_sigma_true,\n",
    "    lambda_low_model,\n",
    "    lambda_high_model,\n",
    "    n_lens,\n",
    "    random_state=rng_np,\n",
    ")\n",
    "\n",
    "# Recenter finite-sample draw so the mock ensemble mean stays close to 1.0\n",
    "lambda_true = lambda_true_raw - np.mean(lambda_true_raw) + 1.0\n",
    "lambda_true = np.clip(lambda_true, lambda_low_model + 1e-3, lambda_high_model - 1e-3)\n",
    "lambda_true = lambda_true - np.mean(lambda_true) + 1.0\n",
    "lambda_true = np.clip(lambda_true, lambda_low_model + 1e-3, lambda_high_model - 1e-3)\n",
    "assert np.abs(np.mean(lambda_true) - 1.0) < 0.01\n",
    "\n",
    "# Per-lens external convergence truth and measurement error\n",
    "kext_sigma = 0.01\n",
    "kext_true = rng_np.normal(0.0, kext_sigma, n_lens)\n",
    "kext_err = np.full(n_lens, 0.01)\n",
    "kext_obs = kext_true.copy()\n",
    "\n",
    "lambda_eff_true = (1.0 - kext_true) * lambda_true\n",
    "\n",
    "# Individual MST measurement error from kinematics (fiducial)\n",
    "ADDITIONAL_MST_BUDGET = 0.04\n",
    "lambda_err_frac_fiducial = 2.0 * (sigma_v_err / sigma_v) + ADDITIONAL_MST_BUDGET\n",
    "lambda_err_fiducial = lambda_err_frac_fiducial * np.abs(lambda_true)\n",
    "\n",
    "# Additional +8% individual MST error scenario (added in quadrature)\n",
    "lambda_err_8pct = np.sqrt(lambda_err_fiducial**2 + (0.08 * np.abs(lambda_true))**2)\n",
    "\n",
    "# Parent-population observations for no-individual-MST scenario\n",
    "N_PARENT = 500\n",
    "lambda_parent_true = tool.truncated_normal(\n",
    "    lambda_mean_true,\n",
    "    lambda_sigma_true,\n",
    "    lambda_low_model,\n",
    "    lambda_high_model,\n",
    "    N_PARENT,\n",
    "    random_state=rng_np,\n",
    ")\n",
    "lambda_parent_err = 0.01 * np.abs(lambda_parent_true)\n",
    "lambda_parent_obs = rng_np.normal(lambda_parent_true, lambda_parent_err)\n",
    "\n",
    "# Time-delay measured true value: unbiased base delays transformed by lambda_eff truth\n",
    "t_measured_true = t_base * lambda_eff_true\n",
    "\n",
    "# Infer FPD true from t = (Ddt/c) * phi * lambda_eff\n",
    "phi_true = (c_km_day * t_measured_true) / (Ddt_obs * Mpc_km * lambda_eff_true)\n",
    "phi_err = 0.03 * np.abs(phi_true)\n",
    "\n",
    "# Clean observation set only\n",
    "t_obs = t_measured_true.copy()\n",
    "phi_obs = phi_true.copy()\n",
    "\n",
    "# Scale phi for numerical stability\n",
    "phi_scale = 10.0 ** int(np.round(-np.log10(np.median(np.abs(phi_true)))))\n",
    "phi_obs_scaled = phi_obs * phi_scale\n",
    "phi_err_scaled = 0.03 * np.abs(phi_true * phi_scale)\n",
    "\n",
    "scenario_data = {\n",
    "    'fiducial_tdcosmo': {\n",
    "        'use_mst_measurement': True,\n",
    "        'use_parent_population': False,\n",
    "        'lambda_obs': lambda_true.copy(),\n",
    "        'lambda_err': lambda_err_fiducial.copy(),\n",
    "    },\n",
    "    'individual_mst_8pct': {\n",
    "        'use_mst_measurement': True,\n",
    "        'use_parent_population': False,\n",
    "        'lambda_obs': lambda_true.copy(),\n",
    "        'lambda_err': lambda_err_8pct.copy(),\n",
    "    },\n",
    "    'parent500_no_individual': {\n",
    "        'use_mst_measurement': False,\n",
    "        'use_parent_population': True,\n",
    "        'lambda_obs': np.zeros_like(lambda_true),\n",
    "        'lambda_err': np.ones_like(lambda_true),\n",
    "    },\n",
    "}\n",
    "\n",
    "print('phi_scale:', phi_scale)\n",
    "print('lambda_mean_true:', lambda_mean_true)\n",
    "print('lambda_sigma_true:', lambda_sigma_true)\n",
    "print('lambda_true_raw_mean:', float(np.mean(lambda_true_raw)))\n",
    "print('lambda_true_centered_mean:', float(np.mean(lambda_true)))\n",
    "print('kext_sigma (true distribution):', kext_sigma)\n",
    "print('kext_err (measurement):', np.unique(kext_err))\n",
    "print('kext_true (%):', np.round(100.0 * kext_true, 3))\n",
    "print('N_PARENT:', N_PARENT)\n",
    "print('lambda_err_frac_fiducial (%):', np.round(100.0 * lambda_err_frac_fiducial, 2))\n",
    "print('lambda_err_8pct_quad (%):', np.round(100.0 * (lambda_err_8pct / np.abs(lambda_true)), 2))\n",
    "print('scenario settings:', {k: (v['use_mst_measurement'], v['use_parent_population']) for k, v in scenario_data.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# LambdaCDM model: sample Omegam/H0 and infer MST population\n",
    "# ---------------------------\n",
    "def quasar_td_lcdm_model(\n",
    "    z_lens,\n",
    "    z_src,\n",
    "    t_obs,\n",
    "    t_err,\n",
    "    phi_obs_scaled,\n",
    "    phi_err_scaled,\n",
    "    phi_scale,\n",
    "    lambda_obs,\n",
    "    lambda_err,\n",
    "    kext_obs,\n",
    "    kext_err,\n",
    "    lambda_parent_obs,\n",
    "    lambda_parent_err,\n",
    "    use_mst_measurement,\n",
    "    use_parent_population,\n",
    "):\n",
    "    Omegam = numpyro.sample('Omegam', dist.Uniform(0.1, 0.5))\n",
    "    h0 = numpyro.sample('h0', dist.Uniform(0.0, 150.0))\n",
    "\n",
    "    cosmo = {'Omegam': Omegam, 'Omegak': 0.0, 'w0': -1.0, 'wa': 0.0, 'h0': h0}\n",
    "\n",
    "    z_lens = jnp.asarray(z_lens)\n",
    "    z_src = jnp.asarray(z_src)\n",
    "    t_obs = jnp.asarray(t_obs)\n",
    "    t_err = jnp.asarray(t_err)\n",
    "    phi_obs_scaled = jnp.asarray(phi_obs_scaled)\n",
    "    phi_err_scaled = jnp.asarray(phi_err_scaled)\n",
    "    phi_scale = jnp.asarray(phi_scale)\n",
    "    lambda_obs = jnp.asarray(lambda_obs)\n",
    "    lambda_err = jnp.asarray(lambda_err)\n",
    "    kext_obs = jnp.asarray(kext_obs)\n",
    "    kext_err = jnp.asarray(kext_err)\n",
    "    lambda_parent_obs = jnp.asarray(lambda_parent_obs)\n",
    "    lambda_parent_err = jnp.asarray(lambda_parent_err)\n",
    "\n",
    "    lambda_mean = numpyro.sample('lambda_mean', dist.Uniform(0.5, 1.5))\n",
    "    lambda_sigma = numpyro.sample('lambda_sigma', dist.LogUniform(0.001, 0.5))\n",
    "\n",
    "    with numpyro.plate('lens', z_lens.shape[0]):\n",
    "        lambda_lens = numpyro.sample(\n",
    "            'lambda_true',\n",
    "            dist.TruncatedNormal(lambda_mean, lambda_sigma, low=lambda_low_model, high=lambda_high_model),\n",
    "        )\n",
    "        kext_lens = numpyro.sample('kext', dist.Normal(0.0, kext_sigma))\n",
    "        if use_mst_measurement:\n",
    "            numpyro.sample('lambda_like', dist.Normal(lambda_lens, lambda_err), obs=lambda_obs)\n",
    "        numpyro.sample('kext_like', dist.Normal(kext_lens, kext_err), obs=kext_obs)\n",
    "\n",
    "    if use_parent_population:\n",
    "        with numpyro.plate('parent_obs', lambda_parent_obs.shape[0]):\n",
    "            lambda_parent_latent = numpyro.sample(\n",
    "                'lambda_parent_true',\n",
    "                dist.TruncatedNormal(lambda_mean, lambda_sigma, low=lambda_low_model, high=lambda_high_model),\n",
    "            )\n",
    "            numpyro.sample('lambda_parent_like', dist.Normal(lambda_parent_latent, lambda_parent_err), obs=lambda_parent_obs)\n",
    "\n",
    "    lambda_eff = (1.0 - kext_lens) * lambda_lens\n",
    "\n",
    "    Dl, Ds, Dls = tool.dldsdls(z_lens, z_src, cosmo, n=20)\n",
    "    Ddt_lens = (1.0 + z_lens) * Dl * Ds / Dls\n",
    "    Ddt_obs = Ddt_lens\n",
    "\n",
    "    c_km_day = tool.c_km_s * 86400.0\n",
    "    Mpc_km = tool.Mpc / 1000.0\n",
    "\n",
    "    with numpyro.plate('td_obs', t_obs.shape[0]):\n",
    "        phi_latent_scaled = numpyro.sample('phi_true_scaled', dist.Normal(phi_obs_scaled, phi_err_scaled))\n",
    "        phi_latent = phi_latent_scaled / phi_scale\n",
    "        t_model_days = (Ddt_obs * Mpc_km / c_km_day) * phi_latent * lambda_eff\n",
    "        numpyro.sample('t_delay_like', dist.Normal(t_model_days, t_err), obs=t_obs)\n",
    "\n",
    "\n",
    "def build_init_values(phi_obs_scaled, use_parent_population):\n",
    "    values = {\n",
    "        'Omegam': jnp.asarray(cosmo_true['Omegam']),\n",
    "        'h0': jnp.asarray(cosmo_true['h0']),\n",
    "        'lambda_mean': jnp.asarray(lambda_mean_true),\n",
    "        'lambda_sigma': jnp.asarray(lambda_sigma_true),\n",
    "        'lambda_true': jnp.asarray(lambda_true),\n",
    "        'kext': jnp.asarray(kext_true),\n",
    "        'phi_true_scaled': jnp.asarray(phi_obs_scaled),\n",
    "    }\n",
    "    if use_parent_population:\n",
    "        values['lambda_parent_true'] = jnp.asarray(lambda_parent_true)\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Run clean-only scenarios\n",
    "# ---------------------------\n",
    "RUN_MCMC = True\n",
    "TARGET_ACCEPT = 0.99\n",
    "NUM_WARMUP = 500\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_CHAINS = 4\n",
    "\n",
    "\n",
    "def run_mcmc(scenario_name, scenario, key):\n",
    "    init_values = build_init_values(phi_obs_scaled, bool(scenario['use_parent_population']))\n",
    "    nuts = NUTS(\n",
    "        quasar_td_lcdm_model,\n",
    "        target_accept_prob=TARGET_ACCEPT,\n",
    "        init_strategy=init_to_value(values=init_values),\n",
    "    )\n",
    "    mcmc = MCMC(\n",
    "        nuts,\n",
    "        num_warmup=NUM_WARMUP,\n",
    "        num_samples=NUM_SAMPLES,\n",
    "        num_chains=NUM_CHAINS,\n",
    "        chain_method='vectorized',\n",
    "        progress_bar=True,\n",
    "    )\n",
    "\n",
    "    mcmc.run(\n",
    "        key,\n",
    "        z_lens=z_lens,\n",
    "        z_src=z_src,\n",
    "        t_obs=t_obs,\n",
    "        t_err=t_err,\n",
    "        phi_obs_scaled=phi_obs_scaled,\n",
    "        phi_err_scaled=phi_err_scaled,\n",
    "        phi_scale=phi_scale,\n",
    "        lambda_obs=scenario['lambda_obs'],\n",
    "        lambda_err=scenario['lambda_err'],\n",
    "        kext_obs=kext_obs,\n",
    "        kext_err=kext_err,\n",
    "        lambda_parent_obs=lambda_parent_obs,\n",
    "        lambda_parent_err=lambda_parent_err,\n",
    "        use_mst_measurement=bool(scenario['use_mst_measurement']),\n",
    "        use_parent_population=bool(scenario['use_parent_population']),\n",
    "    )\n",
    "\n",
    "    extra = mcmc.get_extra_fields(group_by_chain=True)\n",
    "    n_div = int(np.asarray(extra['diverging']).sum())\n",
    "    print(f'[{scenario_name}] divergences:', n_div)\n",
    "\n",
    "    posterior = mcmc.get_samples(group_by_chain=True)\n",
    "    inf_data = az.from_dict(posterior=posterior)\n",
    "    return inf_data\n",
    "\n",
    "\n",
    "def make_single_corner(idata, var_names, outfile, color):\n",
    "    fig = corner(\n",
    "        idata,\n",
    "        var_names=var_names,\n",
    "        labels=var_names,\n",
    "        color=color,\n",
    "        show_titles=False,\n",
    "        levels=[0.68, 0.95],\n",
    "        fill_contours=True,\n",
    "        plot_datapoints=False,\n",
    "        smooth=0.2,\n",
    "        use_math_text=True,\n",
    "        contour_kwargs={'linewidths': 2.5},\n",
    "        hist_kwargs={'density': True, 'linewidth': 2.5},\n",
    "    )\n",
    "    fig.savefig(outfile, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "if RUN_MCMC:\n",
    "    order = [\n",
    "        'fiducial_tdcosmo',\n",
    "        'individual_mst_8pct',\n",
    "        'parent500_no_individual',\n",
    "    ]\n",
    "    color_map = {\n",
    "        'fiducial_tdcosmo': '#2f8aed',\n",
    "        'individual_mst_8pct': '#f48c06',\n",
    "        'parent500_no_individual': '#2ca25f',\n",
    "    }\n",
    "\n",
    "    keys = random.split(random.PRNGKey(SEED), len(order))\n",
    "    inference_results = {}\n",
    "\n",
    "    for i, name in enumerate(order):\n",
    "        scenario = scenario_data[name]\n",
    "        inf_data = run_mcmc(name, scenario, keys[i])\n",
    "        inference_results[name] = inf_data\n",
    "\n",
    "        nc_path = RESULT_DIR / f'test_quasar8_clean3_{name}.nc'\n",
    "        az.to_netcdf(inf_data, nc_path)\n",
    "\n",
    "        trace_vars = ['h0', 'Omegam', 'lambda_mean', 'lambda_sigma']\n",
    "        corner_vars = ['h0', 'Omegam', 'lambda_mean', 'lambda_sigma']\n",
    "\n",
    "        axes = az.plot_trace(inf_data, var_names=trace_vars, compact=True)\n",
    "        fig_trace = axes.ravel()[0].figure\n",
    "        trace_path = RESULT_DIR / f'test_quasar8_clean3_{name}_trace.pdf'\n",
    "        fig_trace.savefig(trace_path, bbox_inches='tight')\n",
    "        plt.close(fig_trace)\n",
    "\n",
    "        print(f\"\\n[{name}] arviz summary\")\n",
    "        print(az.summary(inf_data, var_names=trace_vars, round_to=4))\n",
    "\n",
    "        corner_path = RESULT_DIR / f'test_quasar8_clean3_{name}_corner.pdf'\n",
    "        make_single_corner(\n",
    "            inf_data,\n",
    "            corner_vars,\n",
    "            corner_path,\n",
    "            color_map[name],\n",
    "        )\n",
    "\n",
    "        print('Saved:', nc_path)\n",
    "        print('Saved:', trace_path)\n",
    "        print('Saved:', corner_path)\n",
    "\n",
    "    overlay_vars = ['h0', 'Omegam', 'lambda_mean', 'lambda_sigma']\n",
    "    overlay_ranges = [(60.0, 80.0), (0.1, 0.5), (0.8, 1.2), (0.0, 0.3)]\n",
    "\n",
    "    first = order[0]\n",
    "    fig = corner(\n",
    "        inference_results[first],\n",
    "        var_names=overlay_vars,\n",
    "        labels=overlay_vars,\n",
    "        range=overlay_ranges,\n",
    "        color=color_map[first],\n",
    "        show_titles=False,\n",
    "        levels=[0.68, 0.95],\n",
    "        fill_contours=True,\n",
    "        plot_datapoints=False,\n",
    "        smooth=0.2,\n",
    "        use_math_text=True,\n",
    "        contour_kwargs={'linewidths': 2.5},\n",
    "        hist_kwargs={'density': True, 'linewidth': 2.5},\n",
    "    )\n",
    "\n",
    "    for name in order[1:]:\n",
    "        corner(\n",
    "            inference_results[name],\n",
    "            fig=fig,\n",
    "            var_names=overlay_vars,\n",
    "            labels=overlay_vars,\n",
    "            range=overlay_ranges,\n",
    "            color=color_map[name],\n",
    "            show_titles=False,\n",
    "            levels=[0.68, 0.95],\n",
    "            fill_contours=False,\n",
    "            no_fill_contours=True,\n",
    "            plot_datapoints=False,\n",
    "            smooth=0.2,\n",
    "            use_math_text=True,\n",
    "            contour_kwargs={'linewidths': 2.5},\n",
    "            hist_kwargs={'density': True, 'linewidth': 2.5, 'histtype': 'step'},\n",
    "        )\n",
    "\n",
    "    overlay_path = RESULT_DIR / 'test_quasar8_clean3_overlay_full.pdf'\n",
    "    fig.savefig(overlay_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    print('Saved:', overlay_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}