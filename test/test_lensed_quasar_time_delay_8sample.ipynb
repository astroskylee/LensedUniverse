{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_lensed_quasar_time_delay_8sample\n",
    "\n",
    "8-lens quasar time-delay forecast from `data/test_data.py`.\n",
    "\n",
    "Key logic:\n",
    "- Use only the longest time-delay pair (`max |dt|`) for each target.\n",
    "- TDCOSMO fiducial cosmology: `H0=70`, `Omegam=0.3`.\n",
    "- Set MST population truth to `lambda_mean=1.0`, `lambda_sigma=0.1` and draw per-lens `lambda_true`.\n",
    "- External convergence is per-lens only (no population-level inference):\n",
    "  - `kext_true ~ N(0, 0.01)`\n",
    "  - `kext_obs = clean/noisy`\n",
    "  - `kext_err = 0.01`\n",
    "- Use `lambda_eff = (1-k_ext)*lambda` in both mock generation and inference likelihood.\n",
    "- Use kinematic errors to define per-lens MST measurement uncertainty via `frac(lambda_err)=2*frac(sigma_v_err/sigma_v)`.\n",
    "- Treat provided time delays as unbiased base values and build `t_measured_true = lambda_eff_true * t_base`.\n",
    "- Each scenario runs with both `clean` and `noisy` observations.\n",
    "- Three scenarios:\n",
    "  1) `fiducial_no_extra`: infer lambda population and use MST measurements with no extra 8% MST error.\n",
    "  2) `fiducial_plus8`: infer lambda population and add 8% (`TDCOSMO_increase_error=0.08`) to individual MST measurement error.\n",
    "  3) `population_only_no_mst_measure`: no MST measurement term and fixed known lambda population (`lambda_mean`, `lambda_sigma`).\n",
    "- Inference always samples `Omegam` and `H0`; first two scenarios also sample `lambda_mean` and `lambda_sigma`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import NUTS, MCMC, init_to_value\n",
    "from jax import random\n",
    "import arviz as az\n",
    "from corner import corner\n",
    "\n",
    "os.environ.setdefault('HDF5_USE_FILE_LOCKING', 'FALSE')\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_root = None\n",
    "\n",
    "if (cwd / 'slcosmo').is_dir() and (cwd / 'data').is_dir():\n",
    "    repo_root = cwd\n",
    "elif (cwd / 'LensedUniverse' / 'slcosmo').is_dir():\n",
    "    repo_root = cwd / 'LensedUniverse'\n",
    "else:\n",
    "    for candidate in [cwd, *cwd.parents]:\n",
    "        if (candidate / 'slcosmo').is_dir() and (candidate / 'data').is_dir():\n",
    "            repo_root = candidate\n",
    "            break\n",
    "\n",
    "if repo_root is None:\n",
    "    raise RuntimeError(f'Cannot locate LensedUniverse repo root from cwd={cwd}')\n",
    "\n",
    "workdir = repo_root\n",
    "os.chdir(workdir)\n",
    "if str(workdir) not in sys.path:\n",
    "    sys.path.insert(0, str(workdir))\n",
    "\n",
    "from slcosmo.tools import tool\n",
    "\n",
    "USE_X64 = os.environ.get('SLCOSMO_USE_X64', '0').strip().lower() in {'1', 'true', 'yes', 'y', 'on'}\n",
    "jax.config.update('jax_enable_x64', USE_X64)\n",
    "if USE_X64:\n",
    "    numpyro.enable_x64()\n",
    "if any(d.platform == 'gpu' for d in jax.devices()):\n",
    "    numpyro.set_platform('gpu')\n",
    "else:\n",
    "    numpyro.set_platform('cpu')\n",
    "\n",
    "print('Precision mode:', 'FP64' if USE_X64 else 'FP32')\n",
    "print('Repo root:', workdir)\n",
    "print('JAX devices:', jax.devices())\n",
    "\n",
    "SEED = 42\n",
    "rng_np = np.random.default_rng(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "RESULT_DIR = workdir / 'test'\n",
    "RESULT_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Load 8-lens dataset and keep only the longest delay pair per target\n",
    "# ---------------------------\n",
    "data_path = workdir / 'data' / 'test_data.py'\n",
    "spec = importlib.util.spec_from_file_location('test_data', data_path)\n",
    "test_data = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(test_data)\n",
    "tdcosmo_8lens = test_data.tdcosmo_8lens\n",
    "\n",
    "lens_names = sorted(tdcosmo_8lens.keys())\n",
    "\n",
    "z_lens = []\n",
    "z_src = []\n",
    "sigma_v = []\n",
    "sigma_v_err = []\n",
    "\n",
    "pair_name = []\n",
    "t_base = []\n",
    "t_err = []\n",
    "\n",
    "for name in lens_names:\n",
    "    d = tdcosmo_8lens[name]\n",
    "    z_lens.append(float(d['zl']))\n",
    "    z_src.append(float(d['zs']))\n",
    "    sigma_v.append(float(d['sigma_ap_los_kms']))\n",
    "    sigma_v_err.append(float(d['sigma_ap_los_err_kms']))\n",
    "\n",
    "    td_dict = d['time_delays_days']\n",
    "    p_long = max(td_dict, key=lambda p: abs(float(td_dict[p]['dt'])))\n",
    "    pair_name.append(f'{name}:{p_long}')\n",
    "    dt_val = float(td_dict[p_long]['dt'])\n",
    "    de = 0.5 * (float(td_dict[p_long].get('err_minus', 0.0)) + float(td_dict[p_long].get('err_plus', 0.0)))\n",
    "    t_base.append(abs(dt_val))\n",
    "    t_err.append(de)\n",
    "\n",
    "z_lens = np.asarray(z_lens, dtype=float)\n",
    "z_src = np.asarray(z_src, dtype=float)\n",
    "sigma_v = np.asarray(sigma_v, dtype=float)\n",
    "sigma_v_err = np.asarray(sigma_v_err, dtype=float)\n",
    "\n",
    "t_base = np.asarray(t_base, dtype=float)\n",
    "t_err = np.asarray(t_err, dtype=float)\n",
    "\n",
    "n_lens = z_lens.size\n",
    "n_obs = t_base.size\n",
    "\n",
    "print('N lens:', n_lens)\n",
    "print('N time-delay observations (longest pair only):', n_obs)\n",
    "for i, name in enumerate(lens_names):\n",
    "    print(f'  {i:02d} {name:15s} pair={pair_name[i]} sigma_v={sigma_v[i]:.1f}+-{sigma_v_err[i]:.1f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Build mock truth and observations\n",
    "# ---------------------------\n",
    "cosmo_true = {'Omegam': 0.3, 'Omegak': 0.0, 'w0': -1.0, 'wa': 0.0, 'h0': 70.0}\n",
    "\n",
    "Dl, Ds, Dls = tool.dldsdls(jnp.asarray(z_lens), jnp.asarray(z_src), cosmo_true, n=20)\n",
    "Ddt_lens = np.asarray((1.0 + z_lens) * Dl * Ds / Dls)\n",
    "Ddt_obs = Ddt_lens\n",
    "\n",
    "c_km_day = tool.c_km_s * 86400.0\n",
    "Mpc_km = tool.Mpc / 1000.0\n",
    "\n",
    "# Fixed MST population truth used to generate mock data\n",
    "lambda_mean_true = 1.0\n",
    "lambda_sigma_true = 0.1\n",
    "lambda_low_model = 0.6\n",
    "lambda_high_model = 1.6\n",
    "lambda_true = tool.truncated_normal(\n",
    "    lambda_mean_true,\n",
    "    lambda_sigma_true,\n",
    "    lambda_low_model,\n",
    "    lambda_high_model,\n",
    "    n_lens,\n",
    "    random_state=rng_np,\n",
    ")\n",
    "\n",
    "# Per-lens external convergence truth and measurement error\n",
    "# No population-level inference parameters for k_ext\n",
    "kext_sigma = 0.01\n",
    "kext_true = rng_np.normal(0.0, kext_sigma, n_lens)\n",
    "kext_err = np.full(n_lens, 0.01)\n",
    "kext_obs_clean = kext_true.copy()\n",
    "kext_obs_noisy = rng_np.normal(kext_true, kext_err)\n",
    "\n",
    "lambda_eff_true = (1.0 - kext_true) * lambda_true\n",
    "\n",
    "# Individual MST measurement error from kinematics\n",
    "lambda_err_frac_base = 2.0 * (sigma_v_err / sigma_v)\n",
    "TDCOSMO_increase_error = 0.08\n",
    "lambda_err_frac_plus8 = lambda_err_frac_base + TDCOSMO_increase_error\n",
    "\n",
    "lambda_err_no_extra = lambda_err_frac_base * np.abs(lambda_true)\n",
    "lambda_err_plus8 = lambda_err_frac_plus8 * np.abs(lambda_true)\n",
    "\n",
    "# Time-delay measured true value: unbiased base delays transformed by lambda_eff truth\n",
    "t_measured_true = t_base * lambda_eff_true\n",
    "\n",
    "# Infer FPD true from t = (Ddt/c) * phi * lambda_eff\n",
    "phi_true = (c_km_day * t_measured_true) / (Ddt_obs * Mpc_km * lambda_eff_true)\n",
    "phi_err = 0.05 * np.abs(phi_true)\n",
    "\n",
    "# Clean and noisy observation sets\n",
    "# clean: observed values equal true values\n",
    "# noisy: observed values sampled from measurement uncertainty\n",
    "t_obs_clean = t_measured_true.copy()\n",
    "phi_obs_clean = phi_true.copy()\n",
    "\n",
    "t_obs_noisy = rng_np.normal(t_measured_true, t_err)\n",
    "phi_obs_noisy = rng_np.normal(phi_true, phi_err)\n",
    "\n",
    "# Scale phi for numerical stability\n",
    "phi_scale = 10.0 ** int(np.round(-np.log10(np.median(np.abs(phi_true)))))\n",
    "phi_obs_scaled_clean = phi_obs_clean * phi_scale\n",
    "phi_obs_scaled_noisy = phi_obs_noisy * phi_scale\n",
    "phi_err_scaled = 0.05 * np.abs(phi_true * phi_scale)\n",
    "\n",
    "# Three scenarios\n",
    "# - First two: infer lambda population (lambda_mean, lambda_sigma)\n",
    "# - Third: lambda population is fixed and known\n",
    "scenario_data = {\n",
    "    'fiducial_no_extra': {\n",
    "        'infer_lambda_population': True,\n",
    "        'use_mst_measurement': True,\n",
    "        'lambda_obs_clean': lambda_true.copy(),\n",
    "        'lambda_obs_noisy': rng_np.normal(lambda_true, lambda_err_no_extra),\n",
    "        'lambda_err': lambda_err_no_extra.copy(),\n",
    "        'kext_obs_clean': kext_obs_clean.copy(),\n",
    "        'kext_obs_noisy': kext_obs_noisy.copy(),\n",
    "        'kext_err': kext_err.copy(),\n",
    "    },\n",
    "    'fiducial_plus8': {\n",
    "        'infer_lambda_population': True,\n",
    "        'use_mst_measurement': True,\n",
    "        'lambda_obs_clean': lambda_true.copy(),\n",
    "        'lambda_obs_noisy': rng_np.normal(lambda_true, lambda_err_plus8),\n",
    "        'lambda_err': lambda_err_plus8.copy(),\n",
    "        'kext_obs_clean': kext_obs_clean.copy(),\n",
    "        'kext_obs_noisy': kext_obs_noisy.copy(),\n",
    "        'kext_err': kext_err.copy(),\n",
    "    },\n",
    "    'population_only_no_mst_measure': {\n",
    "        'infer_lambda_population': False,\n",
    "        'use_mst_measurement': False,\n",
    "        'lambda_obs_clean': np.zeros_like(lambda_true),\n",
    "        'lambda_obs_noisy': np.zeros_like(lambda_true),\n",
    "        'lambda_err': np.ones_like(lambda_true),\n",
    "        'kext_obs_clean': kext_obs_clean.copy(),\n",
    "        'kext_obs_noisy': kext_obs_noisy.copy(),\n",
    "        'kext_err': kext_err.copy(),\n",
    "    },\n",
    "}\n",
    "\n",
    "data_modes = {\n",
    "    'clean': {\n",
    "        't_obs': t_obs_clean,\n",
    "        'phi_obs_scaled': phi_obs_scaled_clean,\n",
    "    },\n",
    "    'noisy': {\n",
    "        't_obs': t_obs_noisy,\n",
    "        'phi_obs_scaled': phi_obs_scaled_noisy,\n",
    "    },\n",
    "}\n",
    "\n",
    "print('phi_scale:', phi_scale)\n",
    "print('lambda_mean_true:', lambda_mean_true)\n",
    "print('lambda_sigma_true:', lambda_sigma_true)\n",
    "print('kext_sigma (true distribution):', kext_sigma)\n",
    "print('kext_err (measurement):', np.unique(kext_err))\n",
    "print('kext_true (%):', np.round(100.0 * kext_true, 3))\n",
    "print('TDCOSMO_increase_error (%):', 100.0 * TDCOSMO_increase_error)\n",
    "print('lambda_err_frac_base (%):', np.round(100.0 * lambda_err_frac_base, 2))\n",
    "print('lambda_err_frac_plus8 (%):', np.round(100.0 * lambda_err_frac_plus8, 2))\n",
    "print('scenario settings:', {k: (v['infer_lambda_population'], v['use_mst_measurement']) for k, v in scenario_data.items()})\n",
    "print('data modes:', list(data_modes.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# LambdaCDM model: sample Omegam/H0 and optionally infer lambda population\n",
    "# ---------------------------\n",
    "def quasar_td_lcdm_model(\n",
    "    z_lens,\n",
    "    z_src,\n",
    "    t_obs,\n",
    "    t_err,\n",
    "    phi_obs_scaled,\n",
    "    phi_err_scaled,\n",
    "    phi_scale,\n",
    "    lambda_obs,\n",
    "    lambda_err,\n",
    "    kext_obs,\n",
    "    kext_err,\n",
    "    use_mst_measurement,\n",
    "    infer_lambda_population,\n",
    "):\n",
    "    Omegam = numpyro.sample('Omegam', dist.Uniform(0.1, 0.5))\n",
    "    h0 = numpyro.sample('h0', dist.Uniform(0.0, 150.0))\n",
    "\n",
    "    cosmo = {'Omegam': Omegam, 'Omegak': 0.0, 'w0': -1.0, 'wa': 0.0, 'h0': h0}\n",
    "\n",
    "    z_lens = jnp.asarray(z_lens)\n",
    "    z_src = jnp.asarray(z_src)\n",
    "    t_obs = jnp.asarray(t_obs)\n",
    "    t_err = jnp.asarray(t_err)\n",
    "    phi_obs_scaled = jnp.asarray(phi_obs_scaled)\n",
    "    phi_err_scaled = jnp.asarray(phi_err_scaled)\n",
    "    phi_scale = jnp.asarray(phi_scale)\n",
    "    lambda_obs = jnp.asarray(lambda_obs)\n",
    "    lambda_err = jnp.asarray(lambda_err)\n",
    "    kext_obs = jnp.asarray(kext_obs)\n",
    "    kext_err = jnp.asarray(kext_err)\n",
    "\n",
    "    if infer_lambda_population:\n",
    "        lambda_mean = numpyro.sample(\n",
    "            'lambda_mean',\n",
    "            dist.Uniform(0.5, 1.5),\n",
    "        )\n",
    "        lambda_sigma = numpyro.sample(\n",
    "            'lambda_sigma',\n",
    "            dist.LogUniform(0.001, 0.5),\n",
    "        )\n",
    "    else:\n",
    "        lambda_mean = jnp.asarray(lambda_mean_true)\n",
    "        lambda_sigma = jnp.asarray(lambda_sigma_true)\n",
    "\n",
    "    with numpyro.plate('lens', z_lens.shape[0]):\n",
    "        lambda_lens = numpyro.sample(\n",
    "            'lambda_true',\n",
    "            dist.TruncatedNormal(lambda_mean, lambda_sigma, low=lambda_low_model, high=lambda_high_model),\n",
    "        )\n",
    "        kext_lens = numpyro.sample('kext', dist.Normal(0.0, kext_sigma))\n",
    "        if use_mst_measurement:\n",
    "            numpyro.sample('lambda_like', dist.Normal(lambda_lens, lambda_err), obs=lambda_obs)\n",
    "        numpyro.sample('kext_like', dist.Normal(kext_lens, kext_err), obs=kext_obs)\n",
    "\n",
    "    lambda_eff = (1.0 - kext_lens) * lambda_lens\n",
    "\n",
    "    Dl, Ds, Dls = tool.dldsdls(z_lens, z_src, cosmo, n=20)\n",
    "    Ddt_lens = (1.0 + z_lens) * Dl * Ds / Dls\n",
    "    Ddt_obs = Ddt_lens\n",
    "\n",
    "    c_km_day = tool.c_km_s * 86400.0\n",
    "    Mpc_km = tool.Mpc / 1000.0\n",
    "\n",
    "    with numpyro.plate('td_obs', t_obs.shape[0]):\n",
    "        phi_latent_scaled = numpyro.sample('phi_true_scaled', dist.Normal(phi_obs_scaled, phi_err_scaled))\n",
    "        phi_latent = phi_latent_scaled / phi_scale\n",
    "        t_model_days = (Ddt_obs * Mpc_km / c_km_day) * phi_latent * lambda_eff\n",
    "        numpyro.sample('t_delay_like', dist.Normal(t_model_days, t_err), obs=t_obs)\n",
    "\n",
    "\n",
    "def build_init_values(phi_obs_scaled, infer_lambda_population):\n",
    "    values = {\n",
    "        'Omegam': jnp.asarray(cosmo_true['Omegam']),\n",
    "        'h0': jnp.asarray(cosmo_true['h0']),\n",
    "        'lambda_true': jnp.asarray(lambda_true),\n",
    "        'kext': jnp.asarray(kext_true),\n",
    "        'phi_true_scaled': jnp.asarray(phi_obs_scaled),\n",
    "    }\n",
    "    if infer_lambda_population:\n",
    "        values['lambda_mean'] = jnp.asarray(lambda_mean_true)\n",
    "        values['lambda_sigma'] = jnp.asarray(lambda_sigma_true)\n",
    "    return values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Run three scenarios with clean and noisy data\n",
    "# ---------------------------\n",
    "RUN_MCMC = True\n",
    "TARGET_ACCEPT = 0.95\n",
    "NUM_WARMUP = 500\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_CHAINS = 4\n",
    "\n",
    "\n",
    "def run_mcmc(scenario_name, scenario, mode_name, mode_data, key):\n",
    "    init_values = build_init_values(mode_data['phi_obs_scaled'], bool(scenario['infer_lambda_population']))\n",
    "    nuts = NUTS(\n",
    "        quasar_td_lcdm_model,\n",
    "        target_accept_prob=TARGET_ACCEPT,\n",
    "        init_strategy=init_to_value(values=init_values),\n",
    "    )\n",
    "    mcmc = MCMC(\n",
    "        nuts,\n",
    "        num_warmup=NUM_WARMUP,\n",
    "        num_samples=NUM_SAMPLES,\n",
    "        num_chains=NUM_CHAINS,\n",
    "        chain_method='vectorized',\n",
    "        progress_bar=True,\n",
    "    )\n",
    "\n",
    "    mcmc.run(\n",
    "        key,\n",
    "        z_lens=z_lens,\n",
    "        z_src=z_src,\n",
    "        t_obs=mode_data['t_obs'],\n",
    "        t_err=t_err,\n",
    "        phi_obs_scaled=mode_data['phi_obs_scaled'],\n",
    "        phi_err_scaled=phi_err_scaled,\n",
    "        phi_scale=phi_scale,\n",
    "        lambda_obs=scenario[f'lambda_obs_{mode_name}'],\n",
    "        lambda_err=scenario['lambda_err'],\n",
    "        kext_obs=scenario[f'kext_obs_{mode_name}'],\n",
    "        kext_err=scenario['kext_err'],\n",
    "        use_mst_measurement=bool(scenario['use_mst_measurement']),\n",
    "        infer_lambda_population=bool(scenario['infer_lambda_population']),\n",
    "    )\n",
    "\n",
    "    extra = mcmc.get_extra_fields(group_by_chain=True)\n",
    "    n_div = int(np.asarray(extra['diverging']).sum())\n",
    "    print(f'[{scenario_name} | {mode_name}] divergences:', n_div)\n",
    "\n",
    "    posterior = mcmc.get_samples(group_by_chain=True)\n",
    "    inf_data = az.from_dict(posterior=posterior)\n",
    "    return inf_data\n",
    "\n",
    "\n",
    "def make_single_corner(idata, var_names, outfile, color):\n",
    "    fig = corner(\n",
    "        idata,\n",
    "        var_names=var_names,\n",
    "        labels=var_names,\n",
    "        color=color,\n",
    "        show_titles=False,\n",
    "        levels=[0.68, 0.95],\n",
    "        fill_contours=True,\n",
    "        plot_datapoints=False,\n",
    "        smooth=0.2,\n",
    "        use_math_text=True,\n",
    "        contour_kwargs={'linewidths': 2.5},\n",
    "        hist_kwargs={'density': True, 'linewidth': 2.5},\n",
    "    )\n",
    "    fig.savefig(outfile, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "if RUN_MCMC:\n",
    "    order = ['fiducial_no_extra', 'fiducial_plus8', 'population_only_no_mst_measure']\n",
    "    mode_order = ['clean', 'noisy']\n",
    "\n",
    "    keys = random.split(random.PRNGKey(SEED), len(order) * len(mode_order))\n",
    "    key_idx = 0\n",
    "\n",
    "    inference_results = {mode: {} for mode in mode_order}\n",
    "\n",
    "    for mode in mode_order:\n",
    "        for i, name in enumerate(order):\n",
    "            scenario = scenario_data[name]\n",
    "            mode_data = data_modes[mode]\n",
    "            inf_data = run_mcmc(name, scenario, mode, mode_data, keys[key_idx])\n",
    "            key_idx += 1\n",
    "            inference_results[mode][name] = inf_data\n",
    "\n",
    "            nc_path = RESULT_DIR / f'test_quasar8_{name}_{mode}.nc'\n",
    "            az.to_netcdf(inf_data, nc_path)\n",
    "\n",
    "            trace_vars = ['h0', 'Omegam']\n",
    "            if scenario['infer_lambda_population']:\n",
    "                trace_vars += ['lambda_mean', 'lambda_sigma']\n",
    "\n",
    "            axes = az.plot_trace(inf_data, var_names=trace_vars, compact=True)\n",
    "            fig_trace = axes.ravel()[0].figure\n",
    "            trace_path = RESULT_DIR / f'test_quasar8_{name}_{mode}_trace.pdf'\n",
    "            fig_trace.savefig(trace_path, bbox_inches='tight')\n",
    "            plt.close(fig_trace)\n",
    "\n",
    "            print(f\"\\n[{name} | {mode}] arviz summary\")\n",
    "            print(az.summary(inf_data, var_names=trace_vars, round_to=4))\n",
    "\n",
    "            corner_path = RESULT_DIR / f'test_quasar8_{name}_{mode}_corner.pdf'\n",
    "            make_single_corner(\n",
    "                inf_data,\n",
    "                trace_vars,\n",
    "                corner_path,\n",
    "                '#2f8aed' if i == 0 else ('#f48c06' if i == 1 else '#2ca25f'),\n",
    "            )\n",
    "\n",
    "            print('Saved:', nc_path)\n",
    "            print('Saved:', trace_path)\n",
    "            print('Saved:', corner_path)\n",
    "\n",
    "        # Overlay across scenarios for each data mode (common cosmology only)\n",
    "        fig = corner(\n",
    "            inference_results[mode][order[0]],\n",
    "            var_names=['h0', 'Omegam'],\n",
    "            labels=['h0', 'Omegam'],\n",
    "            color='#2f8aed',\n",
    "            show_titles=False,\n",
    "            levels=[0.68, 0.95],\n",
    "            fill_contours=True,\n",
    "            plot_datapoints=False,\n",
    "            smooth=0.2,\n",
    "            use_math_text=True,\n",
    "            contour_kwargs={'linewidths': 2.5},\n",
    "            hist_kwargs={'density': True, 'linewidth': 2.5},\n",
    "        )\n",
    "        corner(\n",
    "            inference_results[mode][order[1]],\n",
    "            fig=fig,\n",
    "            var_names=['h0', 'Omegam'],\n",
    "            labels=['h0', 'Omegam'],\n",
    "            color='#f48c06',\n",
    "            show_titles=False,\n",
    "            levels=[0.68, 0.95],\n",
    "            fill_contours=True,\n",
    "            plot_datapoints=False,\n",
    "            smooth=0.2,\n",
    "            use_math_text=True,\n",
    "            contour_kwargs={'linewidths': 2.5},\n",
    "            hist_kwargs={'density': True, 'linewidth': 2.5},\n",
    "        )\n",
    "        corner(\n",
    "            inference_results[mode][order[2]],\n",
    "            fig=fig,\n",
    "            var_names=['h0', 'Omegam'],\n",
    "            labels=['h0', 'Omegam'],\n",
    "            color='#2ca25f',\n",
    "            show_titles=False,\n",
    "            levels=[0.68, 0.95],\n",
    "            fill_contours=True,\n",
    "            plot_datapoints=False,\n",
    "            smooth=0.2,\n",
    "            use_math_text=True,\n",
    "            contour_kwargs={'linewidths': 2.5},\n",
    "            hist_kwargs={'density': True, 'linewidth': 2.5},\n",
    "        )\n",
    "        overlay_path = RESULT_DIR / f'test_quasar8_overlay_h0_Omegam_{mode}.pdf'\n",
    "        fig.savefig(overlay_path, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        print('Saved:', overlay_path)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}