{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfa33a0",
   "metadata": {},
   "source": [
    "# test_lens_kinematic\n",
    "\n",
    "Notebook 版的 `hmc_scripts/run_lens_kin_hmc.py`，包含 clean/noisy 两次 HMC、divergence 打印、trace plot 与 overlay corner。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37a01f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ.setdefault('HDF5_USE_FILE_LOCKING', 'FALSE')\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "workdir = Path.cwd()\n",
    "if (workdir / 'hmc_scripts').exists() is False:\n",
    "    workdir = Path('/users/tianli/LensedUniverse')\n",
    "os.chdir(workdir)\n",
    "if str(workdir) not in sys.path:\n",
    "    sys.path.insert(0, str(workdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f076de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision mode: FP32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpyro\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.infer import NUTS, MCMC\n",
    "import arviz as az\n",
    "\n",
    "from slcosmo import tool\n",
    "from hmc_scripts.corner_utils import select_corner_vars, make_overlay_corner\n",
    "\n",
    "USE_X64 = os.environ.get(\"SLCOSMO_USE_X64\", \"0\").strip().lower() in {\"1\", \"true\", \"yes\", \"y\", \"on\"}\n",
    "jax.config.update(\"jax_enable_x64\", USE_X64)\n",
    "if USE_X64:\n",
    "    numpyro.enable_x64()\n",
    "if any(d.platform == \"gpu\" for d in jax.devices()):\n",
    "    numpyro.set_platform(\"gpu\")\n",
    "else:\n",
    "    numpyro.set_platform(\"cpu\")\n",
    "print(\"Precision mode:\", \"FP64\" if USE_X64 else \"FP32\")\n",
    "\n",
    "SEED = 42\n",
    "rng_np = np.random.default_rng(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TEST_MODE = False\n",
    "RESULT_DIR = Path('/mnt/lustre/tianli/LensedUniverse_result')\n",
    "RESULT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = workdir / 'result'\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_DIR = Path(os.environ.get('SLCOSMO_DATA_DIR', str(workdir / 'data')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed0c4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_lens = 5562\n"
     ]
    }
   ],
   "source": [
    "cosmo_true = {'Omegam': 0.32, 'Omegak': 0.0, 'w0': -1.0, 'wa': 0.0, 'h0': 70.0}\n",
    "cosmo_prior = {\n",
    "    'w0_up': 0.0, 'w0_low': -2.0,\n",
    "    'wa_up': 2.0, 'wa_low': -2.0,\n",
    "    'omegak_up': 1.0, 'omegak_low': -1.0,\n",
    "    'h0_up': 80.0, 'h0_low': 60.0,\n",
    "    'omegam_up': 0.5, 'omegam_low': 0.1,\n",
    "}\n",
    "\n",
    "LUT = np.load(DATA_DIR / 'velocity_disp_table.npy')\n",
    "N1, N2, N3, N4 = LUT.shape\n",
    "thetaE_grid = np.linspace(0.5, 3.0, N1)\n",
    "gamma_grid = np.linspace(1.2, 2.8, N2)\n",
    "Re_grid = np.linspace(0.15, 3.0, N3)\n",
    "beta_grid = np.linspace(-0.5, 0.8, N4)\n",
    "jampy_interp = tool.make_4d_interpolant(thetaE_grid, gamma_grid, Re_grid, beta_grid, LUT)\n",
    "\n",
    "Euclid_GG_data = np.loadtxt(DATA_DIR / 'Euclid_len.txt')\n",
    "zl_lens = Euclid_GG_data[:, 0]\n",
    "zs_lens = Euclid_GG_data[:, 1]\n",
    "Ein_lens = Euclid_GG_data[:, 2]\n",
    "re_lens = Euclid_GG_data[:, 5]\n",
    "\n",
    "mask_lens = (Ein_lens >= 0.6) & (re_lens >= 0.25) & (re_lens <= 2.8)\n",
    "zl_lens = zl_lens[mask_lens]\n",
    "zs_lens = zs_lens[mask_lens]\n",
    "thetaE_lens = Ein_lens[mask_lens]\n",
    "re_lens = re_lens[mask_lens]\n",
    "\n",
    "_dl, ds_lens, dls_lens = tool.dldsdls(zl_lens, zs_lens, cosmo_true, n=20)\n",
    "N_lens = len(zl_lens)\n",
    "\n",
    "gamma_true = tool.truncated_normal(2.0, 0.2, 1.6, 2.4, N_lens, random_state=rng_np)\n",
    "beta_true = tool.truncated_normal(0.0, 0.2, -0.4, 0.4, N_lens, random_state=rng_np)\n",
    "vel_model = jampy_interp(thetaE_lens, gamma_true, re_lens, beta_true) * jnp.sqrt(ds_lens / dls_lens)\n",
    "\n",
    "lambda_true = tool.truncated_normal(1.0, 0.05, 0.9, 1.1, N_lens, random_state=rng_np)\n",
    "vel_true = vel_model * jnp.sqrt(lambda_true)\n",
    "\n",
    "theta_E_err = 0.01 * thetaE_lens\n",
    "vel_err = 0.10 * vel_true\n",
    "\n",
    "gamma_obs_clean = gamma_true\n",
    "theta_E_obs_clean = thetaE_lens\n",
    "vel_obs_clean = vel_true\n",
    "\n",
    "gamma_obs_noisy = gamma_true + tool.truncated_normal(0.0, 0.05, -0.2, 0.2, N_lens, random_state=rng_np)\n",
    "theta_E_obs_noisy = thetaE_lens + np.random.normal(0.0, theta_E_err)\n",
    "vel_obs_noisy = np.random.normal(vel_true, vel_err)\n",
    "\n",
    "def build_data(gamma_obs, theta_E_obs, vel_obs):\n",
    "    return {\n",
    "        'zl': zl_lens,\n",
    "        'zs': zs_lens,\n",
    "        'theta_E': theta_E_obs,\n",
    "        'theta_E_err': theta_E_err,\n",
    "        're': re_lens,\n",
    "        'gamma_obs': gamma_obs,\n",
    "        'vel_obs': vel_obs,\n",
    "        'vel_err': vel_err,\n",
    "    }\n",
    "\n",
    "lens_data_clean = build_data(gamma_obs_clean, theta_E_obs_clean, vel_obs_clean)\n",
    "lens_data_noisy = build_data(gamma_obs_noisy, theta_E_obs_noisy, vel_obs_noisy)\n",
    "print('N_lens =', N_lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noisy-dist-note",
   "metadata": {},
   "source": [
    "## Noisy Data Distributions (Before HMC)\\n",
    "Print noisy-data statistics and draw multiple histogram groups before running HMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noisy-dist-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy data summary and histograms (run this before HMC)\\n",
    "vel_true_np = np.asarray(vel_true)\\n",
    "\\n",
    "noisy_obs = {\\n",
    "    'gamma_obs_noisy': np.asarray(gamma_obs_noisy),\\n",
    "    'theta_E_obs_noisy': np.asarray(theta_E_obs_noisy),\\n",
    "    'vel_obs_noisy': np.asarray(vel_obs_noisy),\\n",
    "    'vel_err': np.asarray(vel_err),\\n",
    "}\\n",
    "\\n",
    "noisy_resid = {\\n",
    "    'gamma_noise': np.asarray(gamma_obs_noisy - gamma_true),\\n",
    "    'theta_E_noise': np.asarray(theta_E_obs_noisy - thetaE_lens),\\n",
    "    'vel_noise': np.asarray(vel_obs_noisy - vel_true_np),\\n",
    "    'vel_noise_norm': np.asarray((vel_obs_noisy - vel_true_np) / np.where(vel_err > 0, vel_err, 1.0)),\\n",
    "}\\n",
    "\\n",
    "print('Noisy-data summary (min, p05, median, p95, max, mean, std)')\\n",
    "for name, arr in {**noisy_obs, **noisy_resid}.items():\\n",
    "    q = np.quantile(arr, [0.05, 0.50, 0.95])\\n",
    "    print(\\n",
    "        f'{name:>16}: min={arr.min():.6g}, p05={q[0]:.6g}, med={q[1]:.6g}, ' \\\n",
    "        f'p95={q[2]:.6g}, max={arr.max():.6g}, mean={arr.mean():.6g}, std={arr.std(ddof=1):.6g}'\\n",
    "    )\\n",
    "\\n",
    "fig1, axes1 = plt.subplots(2, 2, figsize=(13, 8))\\n",
    "for ax, (name, arr) in zip(axes1.flat, noisy_obs.items()):\\n",
    "    ax.hist(arr, bins=60, density=True, alpha=0.85, color='tab:blue', edgecolor='white')\\n",
    "    ax.set_title(name)\\n",
    "    ax.grid(alpha=0.25)\\n",
    "fig1.suptitle('Noisy observables distributions', fontsize=13)\\n",
    "fig1.tight_layout()\\n",
    "\\n",
    "fig2, axes2 = plt.subplots(2, 2, figsize=(13, 8))\\n",
    "for ax, (name, arr) in zip(axes2.flat, noisy_resid.items()):\\n",
    "    ax.hist(arr, bins=60, density=True, alpha=0.85, color='tab:orange', edgecolor='white')\\n",
    "    ax.set_title(name)\\n",
    "    ax.grid(alpha=0.25)\\n",
    "fig2.suptitle('Noisy residual distributions', fontsize=13)\\n",
    "fig2.tight_layout()\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74984e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosmology_model(kind, cosmo_prior, sample_h0=True):\n",
    "    cosmo = {\n",
    "        'Omegam': numpyro.sample('Omegam', dist.Uniform(cosmo_prior['omegam_low'], cosmo_prior['omegam_up'])),\n",
    "        'Omegak': 0.0,\n",
    "        'w0': -1.0,\n",
    "        'wa': 0.0,\n",
    "        'h0': 70.0,\n",
    "    }\n",
    "    if kind in ['wcdm', 'owcdm', 'waw0cdm', 'owaw0cdm']:\n",
    "        cosmo['w0'] = numpyro.sample('w0', dist.Uniform(cosmo_prior['w0_low'], cosmo_prior['w0_up']))\n",
    "    if kind in ['waw0cdm', 'owaw0cdm']:\n",
    "        cosmo['wa'] = numpyro.sample('wa', dist.Uniform(cosmo_prior['wa_low'], cosmo_prior['wa_up']))\n",
    "    if kind in ['owcdm', 'owaw0cdm']:\n",
    "        cosmo['Omegak'] = numpyro.sample('Omegak', dist.Uniform(cosmo_prior['omegak_low'], cosmo_prior['omegak_up']))\n",
    "    if sample_h0:\n",
    "        cosmo['h0'] = numpyro.sample('h0', dist.Uniform(cosmo_prior['h0_low'], cosmo_prior['h0_up']))\n",
    "    return cosmo\n",
    "\n",
    "\n",
    "def lens_model(lens_data):\n",
    "    cosmo = cosmology_model('waw0cdm', cosmo_prior, sample_h0=True)\n",
    "\n",
    "    lambda_mean = numpyro.sample('lambda_mean', dist.Uniform(0.9, 1.1))\n",
    "    lambda_sigma = numpyro.sample('lambda_sigma', dist.TruncatedNormal(0.05, 0.5, low=0.0, high=0.2))\n",
    "\n",
    "    gamma_mean = numpyro.sample('gamma_mean', dist.Uniform(1.4, 2.6))\n",
    "    gamma_sigma = numpyro.sample('gamma_sigma', dist.TruncatedNormal(0.2, 0.2, low=0.0, high=0.4))\n",
    "\n",
    "    beta_mean = numpyro.sample('beta_mean', dist.Uniform(-0.3, 0.3))\n",
    "    beta_sigma = numpyro.sample('beta_sigma', dist.TruncatedNormal(0.2, 0.2, low=0.0, high=0.4))\n",
    "\n",
    "    _dl, ds_lens, dls_lens = tool.dldsdls(lens_data['zl'], lens_data['zs'], cosmo, n=20)\n",
    "    N = len(lens_data['zl'])\n",
    "    with numpyro.plate('lens', N):\n",
    "        gamma_i = numpyro.sample('gamma_i', dist.TruncatedNormal(gamma_mean, gamma_sigma, low=1.4, high=2.6))\n",
    "        beta_i = numpyro.sample('beta_i', dist.TruncatedNormal(beta_mean, beta_sigma, low=-0.4, high=0.4))\n",
    "        lambda_lens = numpyro.sample('lambda_lens', dist.TruncatedNormal(lambda_mean, lambda_sigma, low=0.6, high=1.4))\n",
    "        theta_E_i = numpyro.sample('theta_E_i', dist.Normal(lens_data['theta_E'], lens_data['theta_E_err']))\n",
    "        v_interp = jampy_interp(theta_E_i, gamma_i, lens_data['re'], beta_i)\n",
    "        vel_pred = v_interp * jnp.sqrt(ds_lens / dls_lens) * jnp.sqrt(lambda_lens)\n",
    "\n",
    "        numpyro.sample('gamma_obs_lens', dist.Normal(gamma_i, 0.05), obs=lens_data['gamma_obs'])\n",
    "        numpyro.sample('vel_lens_like', dist.Normal(vel_pred, lens_data['vel_err']), obs=lens_data['vel_obs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8ebc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [03:32<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[noisy] divergences: 60\n"
     ]
    }
   ],
   "source": [
    "def run_mcmc(data, key, tag):\n",
    "    if TEST_MODE:\n",
    "        num_warmup, num_samples, num_chains, chain_method = 200, 200, 2, 'sequential'\n",
    "    else:\n",
    "        num_warmup, num_samples, num_chains, chain_method = 500, 1500, 4, 'vectorized'\n",
    "\n",
    "    nuts = NUTS(lens_model, target_accept_prob=0.95)\n",
    "    mcmc = MCMC(\n",
    "        nuts,\n",
    "        num_warmup=num_warmup,\n",
    "        num_samples=num_samples,\n",
    "        num_chains=num_chains,\n",
    "        chain_method=chain_method,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "    mcmc.run(key, lens_data=data)\n",
    "\n",
    "    extra = mcmc.get_extra_fields(group_by_chain=True)\n",
    "    n_div = int(np.asarray(extra['diverging']).sum())\n",
    "    print(f'[{tag}] divergences: {n_div}')\n",
    "\n",
    "    posterior = mcmc.get_samples(group_by_chain=True)\n",
    "    inf_data = az.from_dict(posterior=posterior)\n",
    "    az.to_netcdf(inf_data, RESULT_DIR / f'lens_kin_{tag}.nc')\n",
    "\n",
    "    trace_vars = ['h0', 'Omegam', 'w0', 'wa', 'lambda_mean', 'lambda_sigma', 'gamma_mean', 'gamma_sigma', 'beta_mean', 'beta_sigma']\n",
    "    trace_vars = [v for v in trace_vars if v in inf_data.posterior and inf_data.posterior[v].ndim == 2]\n",
    "    trace_axes = az.plot_trace(inf_data, var_names=trace_vars, compact=False)\n",
    "    trace_fig = np.asarray(trace_axes).ravel()[0].figure\n",
    "    trace_fig.savefig(FIG_DIR / f'lens_kin_trace_{tag}.png', dpi=200, bbox_inches='tight')\n",
    "    plt.close(trace_fig)\n",
    "    return inf_data\n",
    "\n",
    "\n",
    "key = random.PRNGKey(42)\n",
    "key_clean, key_noisy = random.split(key)\n",
    "\n",
    "idata_clean = run_mcmc(lens_data_clean, key_clean, 'clean')\n",
    "idata_noisy = run_mcmc(lens_data_noisy, key_noisy, 'noisy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa926fb6-b61e-4a9c-a9ca-309f2617abea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 2000/2000 [05:42<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[clean] divergences: 26\n"
     ]
    }
   ],
   "source": [
    "idata_clean = run_mcmc(lens_data_clean, key_clean, 'clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4d8853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "/mnt/lustre/tianli/LensedUniverse_result/lens_kin_clean.nc\n",
      "/mnt/lustre/tianli/LensedUniverse_result/lens_kin_noisy.nc\n",
      "/users/tianli/LensedUniverse/result/lens_kin_trace_clean.png\n",
      "/users/tianli/LensedUniverse/result/lens_kin_trace_noisy.png\n",
      "/users/tianli/LensedUniverse/result/lens_kin_corner_overlay.png\n"
     ]
    }
   ],
   "source": [
    "corner_vars = select_corner_vars(\n",
    "    idata_clean,\n",
    "    idata_noisy,\n",
    "    ['h0', 'Omegam', 'w0', 'wa', 'lambda_mean', 'lambda_sigma', 'gamma_mean', 'gamma_sigma', 'beta_mean', 'beta_sigma'],\n",
    ")\n",
    "make_overlay_corner(idata_clean, idata_noisy, corner_vars, FIG_DIR / 'lens_kin_corner_overlay.png')\n",
    "print('Saved:')\n",
    "print(RESULT_DIR / 'lens_kin_clean.nc')\n",
    "print(RESULT_DIR / 'lens_kin_noisy.nc')\n",
    "print(FIG_DIR / 'lens_kin_trace_clean.png')\n",
    "print(FIG_DIR / 'lens_kin_trace_noisy.png')\n",
    "print(FIG_DIR / 'lens_kin_corner_overlay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d80eba-d036-4db6-81af-c89e1b4b221c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Herculens_Tian",
   "language": "python",
   "name": "herculens_tian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
